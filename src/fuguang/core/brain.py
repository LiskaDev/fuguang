
import json
import os
import time
import datetime
import logging
import httpx
import threading
from openai import OpenAI
from .config import ConfigManager
from .mouth import Mouth
from .. import memory as fuguang_memory

logger = logging.getLogger("Fuguang")

class Brain:
    """
    æ€è€ƒä¸è®°å¿†è§’è‰²
    èŒè´£ï¼šAI å®¢æˆ·ç«¯ã€èŠå¤©å†å²ã€è®°å¿†ã€System Prompt
    """

    MAX_HISTORY = 20
    QUICK_LOCAL_TRIGGERS = ["å‡ ç‚¹", "æ—¶é—´", "å‡ å·", "æ—¥æœŸ", "ç”µé‡", "çŠ¶æ€"]

    def __init__(self, config: ConfigManager, mouth: Mouth):
        self.config = config
        self.mouth = mouth

        # AI å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=config.DEEPSEEK_API_KEY,
            base_url=config.DEEPSEEK_BASE_URL,
            timeout=httpx.Timeout(120.0, connect=10.0)
        )

        # é•¿æœŸè®°å¿†ç³»ç»Ÿ
        self.memory_system = fuguang_memory.MemorySystem()

        # çŸ­æœŸå¯¹è¯å†å²
        self.chat_history = []

        # çŠ¶æ€
        self.IS_CREATION_MODE = False

    def load_memory(self) -> dict:
        """åŠ è½½çŸ­æœŸè®°å¿†"""
        if not self.config.MEMORY_FILE.exists():
            return {"user_profile": {}, "short_term_summary": "æš‚æ— è®°å½•"}
        try:
            with open(self.config.MEMORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {"user_profile": {}, "short_term_summary": "æ–‡ä»¶æŸå"}

    def save_memory(self, memory_data: dict):
        """ä¿å­˜çŸ­æœŸè®°å¿†"""
        try:
            with open(self.config.MEMORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(memory_data, f, ensure_ascii=False, indent=4)
            logger.info("ğŸ’¾ è®°å¿†å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"è®°å¿†ä¿å­˜å¤±è´¥: {e}")

    def get_system_prompt(self, dynamic_context: dict = None) -> str:
        """
        ç”ŸæˆåŠ¨æ€ System Prompt
        
        Args:
            dynamic_context: å®æ—¶æ„ŸçŸ¥æ•°æ®ï¼ŒåŒ…å«:
                - app: å½“å‰æ´»åŠ¨çª—å£æ ‡é¢˜
                - clipboard: å‰ªè´´æ¿å†…å®¹
                - user_present: ç”¨æˆ·æ˜¯å¦åœ¨åº§ï¼ˆå¯é€‰ï¼‰
        """
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][datetime.datetime.now().weekday()]
        current_date = f"{datetime.datetime.now().strftime('%Y-%m-%d')} {weekday}"
        mode_status = "ğŸ”“å·²è§£é”" if self.IS_CREATION_MODE else "ğŸ”’å·²é”å®š"

        memory = self.load_memory()
        user_profile = json.dumps(memory.get("user_profile", {}), ensure_ascii=False)
        summary = memory.get("short_term_summary", "æš‚æ— ")

        # æ„å»ºæ„ŸçŸ¥ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†ï¼‰
        perception_section = ""
        if dynamic_context:
            app_name = dynamic_context.get("app", "æœªçŸ¥")
            clipboard = dynamic_context.get("clipboard", "æ— ")
            user_present = dynamic_context.get("user_present", None)
            visual_status = ""
            if user_present is not None:
                visual_status = "æŒ‡æŒ¥å®˜åœ¨åº§ä½ä¸Š" if user_present else "åº§ä½æ— äºº"
            
            perception_section = f"""

ã€å®æ—¶æ„ŸçŸ¥çŠ¶æ€ã€‘
- ç”¨æˆ·æ­£åœ¨æ“ä½œ: {app_name}
- å‰ªè´´æ¿å†…å®¹: {clipboard}
{f'- è§†è§‰çŠ¶æ€: {visual_status}' if visual_status else ''}
ï¼ˆå½“ç”¨æˆ·é—®"è¿™ä¸ª"ã€"è¿™æ®µä»£ç "ã€"å¸®æˆ‘çœ‹çœ‹"æ—¶ï¼ŒæŒ‡çš„å°±æ˜¯å‰ªè´´æ¿å†…å®¹ï¼›å½“ç”¨æˆ·é—®"æˆ‘åœ¨å¹²å˜›"æ—¶è¯·æ ¹æ®å½“å‰çª—å£å›ç­”ï¼‰
"""

        try:
            with open(self.config.SYSTEM_PROMPT_FILE, "r", encoding="utf-8") as f:
                template = f.read()
            prompt = template.format(
                current_time=current_time,
                current_date=current_date,
                mode_status=mode_status,
                history_summary=f"ã€ç”¨æˆ·æ¡£æ¡ˆã€‘{user_profile}\nã€ä¸Šæ¬¡è¯é¢˜æ‘˜è¦ã€‘{summary}"
            )
            # è¿½åŠ æ„ŸçŸ¥ä¿¡æ¯
            return prompt + perception_section
        except Exception:
            return f"ä½ æ˜¯æ²ˆæ‰¶å…‰ï¼Œè¯´è¯ç®€æ´ã€‚[Neutral]{perception_section}"

    def trim_history(self):
        """ä¿®å‰ªå¯¹è¯å†å²ï¼Œé˜²æ­¢è¿‡é•¿"""
        if len(self.chat_history) <= self.MAX_HISTORY * 2:
            return

        target_len = self.MAX_HISTORY * 2 - 10
        for i in range(len(self.chat_history) - target_len, len(self.chat_history)):
            if i >= 0 and self.chat_history[i]["role"] == "user":
                self.chat_history = self.chat_history[i:]
                return

        self.chat_history = self.chat_history[-(self.MAX_HISTORY * 2):]

    def should_auto_respond(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨å“åº”æœ¬åœ°æŒ‡ä»¤"""
        return any(trigger in text for trigger in self.QUICK_LOCAL_TRIGGERS)

    def summarize_and_exit(self):
        """æ•´ç†è®°å¿†å¹¶é€€å‡º"""
        logger.info("æ­£åœ¨æ•´ç†ä»Šæ—¥è®°å¿†...")
        self.mouth.speak("æŒ‡æŒ¥å®˜ï¼Œæ­£åœ¨åŒæ­¥è®°å¿†æ•°æ®...")

        if len(self.chat_history) < 2:
            self.mouth.speak("æ™šå®‰ã€‚")
            os._exit(0)

        conversation_text = ""
        for msg in self.chat_history:
            role = "é˜¿é‘«" if msg["role"] == "user" else "æ‰¶å…‰"
            conversation_text += f"{role}: {msg['content']}\n"

        try:
            summary_prompt = [
                {"role": "system", "content": "è¯·ç®€è¦æ€»ç»“ä»¥ä¸‹å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ã€‚100å­—ä»¥å†…ã€‚"},
                {"role": "user", "content": conversation_text}
            ]
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=summary_prompt,
                max_tokens=200,
                temperature=0.5
            )
            new_summary = response.choices[0].message.content
            logger.info(f"ğŸ“ ä»Šæ—¥æ—¥è®°: {new_summary}")

            mem = self.load_memory()
            old = mem.get("short_term_summary", "")
            mem["short_term_summary"] = f"{new_summary} | (æ—§: {old[:50]}...)"
            self.save_memory(mem)

        except Exception as e:
            logger.error(f"æ€»ç»“å¤±è´¥: {e}")

        self.mouth.speak("è®°å¿†åŒæ­¥å®Œæˆï¼Œæ™šå®‰ã€‚")
        time.sleep(1)
        os._exit(0)

    # ========================
    # ğŸ§  æ ¸å¿ƒå¯¹è¯æ–¹æ³• (Function Calling)
    # ========================
    def chat(self, user_input: str, system_content: str, tools_schema: list, tool_executor) -> str:
        """
        æ ¸å¿ƒå¯¹è¯æ–¹æ³•ï¼šæ”¯æŒ Function Calling (å·¥å…·è°ƒç”¨)
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            system_content: å®Œæ•´çš„ System Promptï¼ˆåŒ…å«è®°å¿†ï¼‰
            tools_schema: å·¥å…·å®šä¹‰åˆ—è¡¨
            tool_executor: å·¥å…·æ‰§è¡Œå‡½æ•° (func_name, func_args) -> result
            
        Returns:
            AI çš„æœ€ç»ˆå›å¤æ–‡æœ¬
        """
        messages = [{"role": "system", "content": system_content}]
        messages.extend(self.chat_history)
        messages.append({"role": "user", "content": user_input})
        
        # [è°ƒæ•´] å¢åŠ æ€è€ƒè½®æ¬¡ä¸Šé™ï¼Œä»¥æ”¯æŒå¤æ‚çš„è¿ç»­ä»»åŠ¡ (å¦‚: æ‰“å¼€ç½‘é¡µ -> æˆªå›¾ -> åˆ†æ -> æ€»ç»“)
        max_iterations = 6
        iteration = 0
        ai_reply = ""
        
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"ğŸ¤– AIæ€è€ƒè½®æ¬¡: {iteration}")
            
            # è°ƒç”¨ DeepSeek
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                tools=tools_schema,
                tool_choice="auto",
                stream=False,
                temperature=0.8,
                max_tokens=4096
            )
            
            message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if message.tool_calls:
                logger.info(f"ğŸ”§ AIè¯·æ±‚ä½¿ç”¨å·¥å…·: {len(message.tool_calls)} ä¸ª")
                
                # æŠŠ AI çš„å·¥å…·è°ƒç”¨æ„å›¾åŠ å…¥å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
                for tool_call in message.tool_calls:
                    func_name = tool_call.function.name
                    func_args = json.loads(tool_call.function.arguments)
                    
                    logger.info(f"ğŸ“ è°ƒç”¨å·¥å…·: {func_name}")
                    result = tool_executor(func_name, func_args)
                    
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
                
                # ç»§ç»­ä¸‹ä¸€è½®ï¼Œè®© AI æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆå›å¤
                continue
            
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è·å–å›å¤
                ai_reply = message.content
                break
        
        else:
            # è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
            ai_reply = "æŒ‡æŒ¥å®˜ï¼Œè¿™ä¸ªé—®é¢˜æœ‰ç‚¹å¤æ‚ï¼Œæˆ‘éœ€è¦æ›´å¤šæ—¶é—´æ€è€ƒ..."
        
        # æ›´æ–°å¯¹è¯å†å²
        self.chat_history.append({"role": "user", "content": user_input})
        self.chat_history.append({"role": "assistant", "content": ai_reply})
        self.trim_history()
        
        # ä¿å­˜äº¤äº’æ—¶é—´
        current_mem = self.load_memory()
        current_mem["last_interaction"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.save_memory(current_mem)
        
        # æ½œæ„è¯†è®°å¿†ï¼šåå°åˆ†æå¯¹è¯
        self.analyze_and_store_memory(user_input, ai_reply)
        
        return ai_reply

    # ========================
    # ğŸ§  æ½œæ„è¯†è®°å¿†ç³»ç»Ÿ (Subconscious Memory)
    # ========================
    def analyze_and_store_memory(self, user_text: str, ai_reply: str):
        """
        è®© AI åæ€åˆšæ‰çš„å¯¹è¯ï¼Œæå–æœ‰ä»·å€¼çš„è®°å¿†ã€‚
        åœ¨åå°çº¿ç¨‹è¿è¡Œï¼Œä¸å¡ä½å¯¹è¯ã€‚
        """
        def _background_task():
            # 1. æ„é€ ä¸“é—¨ç”¨æ¥æå–è®°å¿†çš„ Prompt
            reflection_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œæå–å…³äºç”¨æˆ·çš„ã€é•¿æœŸäº‹å®ã€‘æˆ–ã€é‡è¦åå¥½ã€‘ã€‚

ç”¨æˆ·è¯´ï¼š{user_text}
AIå›å¤ï¼š{ai_reply}

ã€æå–è§„åˆ™ã€‘
- åªæå–å¯ä»¥é•¿æœŸè®°ä½çš„äº‹å®ï¼ˆå¦‚ï¼šç”¨æˆ·çš„è®¡åˆ’ã€åå¥½ã€åŒæ¶ã€ä¹ æƒ¯ã€äººé™…å…³ç³»ç­‰ï¼‰
- ä¸è¦æå–ä¸´æ—¶æ€§ä¿¡æ¯ï¼ˆå¦‚ï¼šä»Šå¤©å¤©æ°”ã€æ­£åœ¨åšçš„äº‹ï¼‰
- å¦‚æœæ²¡æœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¾“å‡º None

ã€è¾“å‡ºè¦æ±‚ã€‘
å¦‚æœæœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦Markdownï¼Œä¸è¦åºŸè¯ï¼‰ï¼š
{{"content": "é™ˆè¿°å¥æ ¼å¼çš„äº‹å®", "importance": 1åˆ°5çš„æ•´æ•°}}

importance ç­‰çº§è¯´æ˜ï¼š
- 5: æ ¸å¿ƒèº«ä»½/æ°¸ä¹…åå¥½ï¼ˆå¦‚ï¼šåå­—ã€MBTIã€ç»å¯¹ç¦å¿Œï¼‰
- 4: é‡è¦è®¡åˆ’/å…³ç³»ï¼ˆå¦‚ï¼šè€ƒé©¾ç…§ã€å¥³æœ‹å‹å«ä»€ä¹ˆï¼‰
- 3: ä¸€èˆ¬åå¥½ï¼ˆå¦‚ï¼šå–œæ¬¢åƒç”œé£Ÿï¼‰
- 2: ä¸´æ—¶çŠ¶æ€ï¼ˆå¦‚ï¼šæœ€è¿‘åœ¨å­¦Pythonï¼‰
- 1: çç¢ä¿¡æ¯

ç¤ºä¾‹è¾“å‡ºï¼š
{{"content": "æŒ‡æŒ¥å®˜æ‰“ç®—ä¸‹ä¸ªæœˆè€ƒé©¾ç…§", "importance": 4}}
"""
            
            try:
                # 2. è°ƒç”¨ LLMï¼ˆéæµå¼ï¼Œè§£æ JSONï¼‰
                response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": reflection_prompt}],
                    max_tokens=150,
                    temperature=0.3  # ä½æ¸©åº¦ï¼Œæ›´ç¨³å®š
                )
                result = response.choices[0].message.content.strip()
                
                # 3. æ£€æŸ¥æ˜¯å¦æœ‰å€¼å¾—è®°å¿†çš„å†…å®¹
                if "None" in result or "none" in result or "{" not in result:
                    return  # æ²¡ä»€ä¹ˆå¥½è®°çš„
                
                # 4. è§£æ JSON
                # æ¸…æ´—å¯èƒ½çš„ Markdown åŒ…è£¹
                clean_json = result.replace("```json", "").replace("```", "").strip()
                memory_item = json.loads(clean_json)
                
                content = memory_item.get("content", "")
                importance = memory_item.get("importance", 3)
                
                if not content:
                    return
                
                # 5. å­˜å…¥é•¿æœŸè®°å¿†
                self.memory_system.add_memory(content, importance)
                logger.info(f"ğŸ§  [æ½œæ„è¯†] å·²è‡ªåŠ¨å½’æ¡£è®°å¿†ï¼š{content} (é‡è¦åº¦: {importance})")
                
            except json.JSONDecodeError as e:
                logger.debug(f"æ½œæ„è¯†è®°å¿†è§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"æ½œæ„è¯†è®°å¿†æå–å¤±è´¥: {e}")
        
        # å¯åŠ¨åå°çº¿ç¨‹ï¼Œä¸é˜»å¡ä¸»å¯¹è¯
        thread = threading.Thread(target=_background_task, daemon=True)
        thread.start()
