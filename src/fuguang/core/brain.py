import json
import os
import sys
import time
import datetime
import logging
import httpx
import threading
from openai import OpenAI, APITimeoutError, APIConnectionError, RateLimitError, APIStatusError
from .config import ConfigManager
from .mouth import Mouth
from .memory import MemoryBank  # [Migration] Use new ChromaDB memory

logger = logging.getLogger("Fuguang")

class Brain:
    """
    æ€è€ƒä¸è®°å¿†è§’è‰²
    èŒè´£ï¼šAI å®¢æˆ·ç«¯ã€èŠå¤©å†å²ã€è®°å¿†ã€System Prompt
    """

    MAX_HISTORY = 20
    QUICK_LOCAL_TRIGGERS = ["å‡ ç‚¹", "æ—¶é—´", "å‡ å·", "æ—¥æœŸ", "ç”µé‡", "çŠ¶æ€"]

    def __init__(self, config: ConfigManager, mouth: Mouth):
        self.config = config
        self.mouth = mouth

        # AI å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=config.DEEPSEEK_API_KEY,
            base_url=config.DEEPSEEK_BASE_URL,
            timeout=httpx.Timeout(120.0, connect=10.0)
        )

        # [Migration] é•¿æœŸè®°å¿†ç³»ç»Ÿ (ChromaDB)
        self.memory_system = MemoryBank(
            persist_dir=str(self.config.PROJECT_ROOT / "data" / "memory_db"),
            obsidian_vault_path=getattr(self.config, 'OBSIDIAN_VAULT_PATH', '')
        )

        # çŸ­æœŸå¯¹è¯å†å²
        self.chat_history = []

        # çŠ¶æ€
        self.IS_CREATION_MODE = False
        
        # ğŸ”¥ æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
        self.performance_log = []  # è®°å½•æ¯æ¬¡ä»»åŠ¡çš„æ€§èƒ½æ•°æ®
        self.system_hints = []  # å­˜å‚¨ç»™AIçš„ç³»ç»Ÿæç¤ºï¼ˆå¦‚æ€§èƒ½è­¦å‘Šï¼‰
        
        # v2.1 æ–°å¢ï¼šå¯åŠ¨æ—¶é¢„åŸ‹å…³é”®é…æ–¹ï¼ˆimportance=5ï¼Œä¸ä¼šè¢«è‡ªåŠ¨å­¦ä¹ è¦†ç›–ï¼‰
        self._ensure_critical_recipes()

    def load_memory(self) -> dict:
        """åŠ è½½çŸ­æœŸè®°å¿†"""
        if not self.config.MEMORY_FILE.exists():
            return {"user_profile": {}, "short_term_summary": "æš‚æ— è®°å½•"}
        try:
            with open(self.config.MEMORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {"user_profile": {}, "short_term_summary": "æ–‡ä»¶æŸå"}

    def save_memory(self, memory_data: dict):
        """ä¿å­˜çŸ­æœŸè®°å¿†"""
        try:
            with open(self.config.MEMORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(memory_data, f, ensure_ascii=False, indent=4)
            logger.info("ğŸ’¾ è®°å¿†å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"è®°å¿†ä¿å­˜å¤±è´¥: {e}")

    def get_system_prompt(self, dynamic_context: dict = None) -> str:
        """
        ç”ŸæˆåŠ¨æ€ System Prompt
        
        Args:
            dynamic_context: å®æ—¶æ„ŸçŸ¥æ•°æ®ï¼ŒåŒ…å«:
                - app: å½“å‰æ´»åŠ¨çª—å£æ ‡é¢˜
                - clipboard: å‰ªè´´æ¿å†…å®¹
                - user_present: ç”¨æˆ·æ˜¯å¦åœ¨åº§ï¼ˆå¯é€‰ï¼‰
        """
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][datetime.datetime.now().weekday()]
        current_date = f"{datetime.datetime.now().strftime('%Y-%m-%d')} {weekday}"
        mode_status = "ğŸ”“å·²è§£é”" if self.IS_CREATION_MODE else "ğŸ”’å·²é”å®š"

        memory = self.load_memory()
        user_profile = json.dumps(memory.get("user_profile", {}), ensure_ascii=False)
        summary = memory.get("short_term_summary", "æš‚æ— ")

        # æ„å»ºæ„ŸçŸ¥ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†ï¼‰
        perception_section = ""
        if dynamic_context:
            app_name = dynamic_context.get("app", "æœªçŸ¥")
            clipboard = dynamic_context.get("clipboard", "æ— ")
            user_present = dynamic_context.get("user_present", None)
            visual_status = ""
            if user_present is not None:
                visual_status = "æŒ‡æŒ¥å®˜åœ¨åº§ä½ä¸Š" if user_present else "åº§ä½æ— äºº"
            
            perception_section = f"""

ã€å®æ—¶æ„ŸçŸ¥çŠ¶æ€ã€‘
- ç”¨æˆ·æ­£åœ¨æ“ä½œ: {app_name}
- å‰ªè´´æ¿å†…å®¹: {clipboard}
{f'- è§†è§‰çŠ¶æ€: {visual_status}' if visual_status else ''}
ï¼ˆå½“ç”¨æˆ·é—®"è¿™ä¸ª"ã€"è¿™æ®µä»£ç "ã€"å¸®æˆ‘çœ‹çœ‹"æ—¶ï¼ŒæŒ‡çš„å°±æ˜¯å‰ªè´´æ¿å†…å®¹ï¼›å½“ç”¨æˆ·é—®"æˆ‘åœ¨å¹²å˜›"æ—¶è¯·æ ¹æ®å½“å‰çª—å£å›ç­”ï¼‰
"""

        try:
            with open(self.config.SYSTEM_PROMPT_FILE, "r", encoding="utf-8") as f:
                template = f.read()
            prompt = template.format(
                current_time=current_time,
                current_date=current_date,
                mode_status=mode_status,
                history_summary=f"ã€ç”¨æˆ·æ¡£æ¡ˆã€‘{user_profile}\nã€ä¸Šæ¬¡è¯é¢˜æ‘˜è¦ã€‘{summary}"
            )
            # è¿½åŠ æ„ŸçŸ¥ä¿¡æ¯
            return prompt + perception_section
        except Exception:
            return f"ä½ æ˜¯æ²ˆæ‰¶å…‰ï¼Œè¯´è¯ç®€æ´ã€‚[Neutral]{perception_section}"

    def trim_history(self):
        """ä¿®å‰ªå¯¹è¯å†å²ï¼Œé˜²æ­¢è¿‡é•¿"""
        if len(self.chat_history) <= self.MAX_HISTORY * 2:
            return

        target_len = self.MAX_HISTORY * 2 - 10
        start_idx = max(0, len(self.chat_history) - target_len)  # [ä¿®å¤L-5] é˜²æ­¢è´Ÿç´¢å¼•
        for i in range(start_idx, len(self.chat_history)):
            if i >= 0 and self.chat_history[i]["role"] == "user":
                self.chat_history = self.chat_history[i:]
                return

        self.chat_history = self.chat_history[-(self.MAX_HISTORY * 2):]

    def should_auto_respond(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨å“åº”æœ¬åœ°æŒ‡ä»¤"""
        return any(trigger in text for trigger in self.QUICK_LOCAL_TRIGGERS)

    def summarize_and_exit(self):
        """æ•´ç†è®°å¿†å¹¶é€€å‡º"""
        logger.info("æ­£åœ¨æ•´ç†ä»Šæ—¥è®°å¿†...")
        self.mouth.speak("æŒ‡æŒ¥å®˜ï¼Œæ­£åœ¨åŒæ­¥è®°å¿†æ•°æ®...")

        if len(self.chat_history) < 2:
            self.mouth.speak("æ™šå®‰ã€‚")
            sys.exit(0)  # [ä¿®å¤H-1] ä½¿ç”¨ sys.exit æ›¿ä»£ os._exitï¼Œå…è®¸ finally/atexit æ¸…ç†

        conversation_text = ""
        for msg in self.chat_history:
            role = "é˜¿é‘«" if msg["role"] == "user" else "æ‰¶å…‰"
            conversation_text += f"{role}: {msg['content']}\n"

        try:
            summary_prompt = [
                {"role": "system", "content": "è¯·ç®€è¦æ€»ç»“ä»¥ä¸‹å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ã€‚100å­—ä»¥å†…ã€‚"},
                {"role": "user", "content": conversation_text}
            ]
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=summary_prompt,
                max_tokens=200,
                temperature=0.5
            )
            new_summary = response.choices[0].message.content
            logger.info(f"ğŸ“ ä»Šæ—¥æ—¥è®°: {new_summary}")

            mem = self.load_memory()
            old = mem.get("short_term_summary", "")
            mem["short_term_summary"] = f"{new_summary} | (æ—§: {old[:50]}...)"
            self.save_memory(mem)

        except Exception as e:
            logger.error(f"æ€»ç»“å¤±è´¥: {e}")

        self.mouth.speak("è®°å¿†åŒæ­¥å®Œæˆï¼Œæ™šå®‰ã€‚")
        time.sleep(1)
        sys.exit(0)  # [ä¿®å¤H-1] ä½¿ç”¨ sys.exit æ›¿ä»£ os._exit

    # ========================
    # ğŸ§  æ ¸å¿ƒå¯¹è¯æ–¹æ³• (Function Calling)
    # ========================
    def chat(self, user_input: str, system_content: str, tools_schema: list, tool_executor) -> str:
        """
        æ ¸å¿ƒå¯¹è¯æ–¹æ³•ï¼šæ”¯æŒ Function Calling (å·¥å…·è°ƒç”¨)
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            system_content: å®Œæ•´çš„ System Promptï¼ˆåŒ…å«è®°å¿†ï¼‰
            tools_schema: å·¥å…·å®šä¹‰åˆ—è¡¨
            tool_executor: å·¥å…·æ‰§è¡Œå‡½æ•° (func_name, func_args) -> result
            
        Returns:
            AI çš„æœ€ç»ˆå›å¤æ–‡æœ¬
        """
        # ğŸ”¥ æ€§èƒ½ç›‘æ§ï¼šè®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        tool_calls_list = []  # è®°å½•æœ¬æ¬¡è°ƒç”¨çš„æ‰€æœ‰å·¥å…·
        
        # æ³¨å…¥ç³»ç»Ÿæç¤ºï¼ˆå¦‚æ€§èƒ½è­¦å‘Šï¼‰
        if self.system_hints:
            hints_text = "\n".join(self.system_hints)
            system_content += f"\n\n{hints_text}\n"
            self.system_hints.clear()  # æ¸…ç©ºæç¤ºï¼Œåªæ˜¾ç¤ºä¸€æ¬¡
        
        # v2.1 æ–°å¢ï¼šæŠŠé…æ–¹å•ç‹¬å¼ºåŒ–æ³¨å…¥åˆ° user_input å‰é¢
        # åŸæ¥é…æ–¹æ··åœ¨ system_prompt é‡Œå®¹æ˜“è¢«æ·¹æ²¡
        # ç°åœ¨æŠŠé…æ–¹ä½œä¸ºç‹¬ç«‹çš„"ä»»åŠ¡å‰æ£€æŸ¥"æ³¨å…¥åˆ°ç”¨æˆ·æ¶ˆæ¯å‰
        recipe_reminder = self.memory_system.recall_recipe(user_input, n_results=4)
        if recipe_reminder:
            user_input_with_recipe = f"""ã€âš¡ æ‰§è¡Œå‰å¿…è¯»é…æ–¹ - è¿™æ˜¯å¼ºåˆ¶è§„èŒƒï¼Œä¸æ˜¯å»ºè®®ã€‘
{recipe_reminder}

---
ç”¨æˆ·æŒ‡ä»¤ï¼š{user_input}"""
        else:
            user_input_with_recipe = user_input
        
        messages = [{"role": "system", "content": system_content}]
        messages.extend(self.chat_history)
        messages.append({"role": "user", "content": user_input_with_recipe})
        
        # [è°ƒæ•´] å¢åŠ æ€è€ƒè½®æ¬¡ä¸Šé™ï¼Œä»¥æ”¯æŒå¤æ‚çš„è¿ç»­ä»»åŠ¡ (å¦‚: æ‰“å¼€ç½‘é¡µ -> æˆªå›¾ -> åˆ†æ -> æ€»ç»“)
        max_iterations = 15
        iteration = 0
        ai_reply = ""
        
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"ğŸ¤– AIæ€è€ƒè½®æ¬¡: {iteration}")
            
            # è°ƒç”¨ DeepSeekï¼ˆå¸¦é‡è¯• + é™çº§ï¼‰
            response = None
            for attempt in range(3):  # æœ€å¤šé‡è¯• 3 æ¬¡
                try:
                    response = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=messages,
                        tools=tools_schema,
                        tool_choice="auto",
                        stream=False,
                        temperature=0.8,
                        max_tokens=4096
                    )
                    break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                except (APITimeoutError, APIConnectionError) as e:
                    wait = 2 ** attempt  # 1s, 2s, 4s æŒ‡æ•°é€€é¿
                    logger.warning(f"âš ï¸ API ç½‘ç»œé”™è¯¯ (ç¬¬{attempt+1}æ¬¡): {e}ï¼Œ{wait}ç§’åé‡è¯•...")
                    time.sleep(wait)
                except RateLimitError as e:
                    wait = 5 * (attempt + 1)  # 5s, 10s, 15s
                    logger.warning(f"âš ï¸ API é™æµ (ç¬¬{attempt+1}æ¬¡): {e}ï¼Œ{wait}ç§’åé‡è¯•...")
                    time.sleep(wait)
                except APIStatusError as e:
                    logger.error(f"âŒ API çŠ¶æ€é”™è¯¯: {e.status_code} {e.message}")
                    break  # æœåŠ¡ç«¯é”™è¯¯ä¸é‡è¯•
                except Exception as e:
                    logger.error(f"âŒ API æœªçŸ¥é”™è¯¯: {e}")
                    break
            
            if response is None:
                ai_reply = "æŒ‡æŒ¥å®˜ï¼Œæˆ‘çš„ç½‘ç»œå¥½åƒä¸å¤ªç¨³å®šï¼Œè¿æ¥ä¸ä¸ŠæœåŠ¡å™¨â€¦ç­‰ä¸€ä¸‹å†è¯•è¯•ï¼Ÿ[Sorrow]"
                break
            
            message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if message.tool_calls:
                logger.info(f"ğŸ”§ AIè¯·æ±‚ä½¿ç”¨å·¥å…·: {len(message.tool_calls)} ä¸ª")
                
                # æŠŠ AI çš„å·¥å…·è°ƒç”¨æ„å›¾åŠ å…¥å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
                for tool_call in message.tool_calls:
                    func_name = tool_call.function.name
                    
                    # [ä¿®å¤C-2] é˜²æ­¢ API è¿”å›ç•¸å½¢ JSON å¯¼è‡´å´©æºƒ
                    try:
                        func_args = json.loads(tool_call.function.arguments)
                    except (json.JSONDecodeError, TypeError) as e:
                        logger.error(f"å·¥å…·å‚æ•°è§£æå¤±è´¥: {func_name}, åŸå§‹å‚æ•°: {tool_call.function.arguments}, é”™è¯¯: {e}")
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": f"å‚æ•°è§£æé”™è¯¯: {e}"
                        })
                        continue
                    
                    logger.info(f"ğŸ“ è°ƒç”¨å·¥å…·: {func_name}")
                    tool_calls_list.append(func_name)  # ğŸ”¥ è®°å½•å·¥å…·è°ƒç”¨
                    
                    # å·¥å…·æ‰§è¡Œè¶…æ—¶ä¿æŠ¤ï¼ˆ30ç§’ï¼‰
                    try:
                        result = tool_executor(func_name, func_args)
                    except Exception as e:
                        logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {func_name} â†’ {e}")
                        result = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}"
                    
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
                
                # ç»§ç»­ä¸‹ä¸€è½®ï¼Œè®© AI æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆå›å¤
                continue
            
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è·å–å›å¤
                ai_reply = message.content
                break
        
        else:
            # è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
            ai_reply = "æŒ‡æŒ¥å®˜ï¼Œè¿™ä¸ªé—®é¢˜æœ‰ç‚¹å¤æ‚ï¼Œæˆ‘éœ€è¦æ›´å¤šæ—¶é—´æ€è€ƒ..."
        
        # ğŸ”¥ æ€§èƒ½ç›‘æ§ï¼šè®°å½•ç»“æŸæ—¶é—´å’Œç»Ÿè®¡æ•°æ®
        elapsed_time = time.time() - start_time
        tool_count = len(tool_calls_list)
        
        # è®°å½•åˆ°æ€§èƒ½æ—¥å¿—ï¼ˆä¿ç•™æœ€è¿‘20æ¡ï¼‰
        self.performance_log.append({
            "task": user_input[:50],  # æˆªå–å‰50å­—ç¬¦
            "time": round(elapsed_time, 2),
            "steps": tool_count,
            "tools_used": tool_calls_list,
            "timestamp": datetime.datetime.now().strftime("%H:%M:%S")
        })
        if len(self.performance_log) > 20:
            self.performance_log.pop(0)  # ç§»é™¤æœ€æ—§çš„è®°å½•
        
        logger.info(f"â±ï¸ [æ€§èƒ½] æœ¬æ¬¡ä»»åŠ¡è€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œè°ƒç”¨å·¥å…·: {tool_count}ä¸ª")
        
        # ğŸ”¥ æ€§èƒ½è­¦å‘Šï¼šå¦‚æœå¤ªæ…¢æˆ–è°ƒç”¨å¤ªå¤šå·¥å…·ï¼Œä¸‹æ¬¡å¼ºåˆ¶æ‰§è¡Œä¼˜åŒ–è§„åˆ™
        if elapsed_time > 5 and tool_count > 2:
            # v2.1 ä¿®å¤ï¼šä»"å»ºè®®"æ”¹ä¸º"å¼ºåˆ¶è§„åˆ™"
            # åŸæ¥çš„æªè¾æ˜¯"è¯·åæ€"ï¼ŒAI å¯ä»¥å¿½ç•¥
            # ç°åœ¨æ”¹ä¸º"ç¦æ­¢/å¿…é¡»"ï¼Œå¼ºåˆ¶çº¦æŸè¡Œä¸º
            warning = f"""ã€ğŸš¨ å¼ºåˆ¶æ‰§è¡Œè§„åˆ™ - ä¸Šæ¬¡ä»»åŠ¡è¿è§„ã€‘
ä¸Šæ¬¡ä»»åŠ¡è€—æ—¶ {elapsed_time:.1f}ç§’ï¼Œè°ƒç”¨äº† {tool_count} ä¸ªå·¥å…·ï¼ˆè¶…æ ‡ï¼‰ã€‚
è¿è§„å·¥å…·é“¾ï¼š{' â†’ '.join(tool_calls_list[-8:])}

æœ¬æ¬¡ä»»åŠ¡ã€ç¦æ­¢ã€‘é‡å¤ä»¥ä¸‹è¡Œä¸ºï¼š
âŒ ç¦æ­¢è¿ç»­è°ƒç”¨è¶…è¿‡ 2 æ¬¡ç›¸åŒå·¥å…·ï¼ˆå¦‚é‡å¤ write_file / list_directoryï¼‰
âŒ ç¦æ­¢åœ¨å†™æ–‡ä»¶å‰å…ˆ list_directory æ¢ç´¢è·¯å¾„ï¼ˆç›´æ¥ä½¿ç”¨å·²çŸ¥è·¯å¾„ï¼‰
âŒ ç¦æ­¢å¤šæ¬¡å°è¯•å†™åŒä¸€ä¸ªæ–‡ä»¶ï¼ˆä¸€æ¬¡å†™å¯¹ï¼‰

æœ¬æ¬¡ä»»åŠ¡ã€å¿…é¡»ã€‘éµå®ˆï¼š
âœ… Obsidian å†™æ–‡ä»¶ï¼šç›´æ¥ç”¨ mcp_obsidian_write_fileï¼Œè·¯å¾„æ ¼å¼ "Notes/æ–‡ä»¶å.md"
âœ… GitHub æœç´¢ï¼šä¸€æ¬¡æ€§æœç´¢å®Œæ‰€æœ‰ç»“æœï¼Œç¦æ­¢å¾ªç¯è°ƒç”¨ search_repositories
âœ… åˆ›å»ºæ–‡ä»¶ï¼šç”¨ create_file_directlyï¼Œç¦æ­¢æ‰“å¼€è®°äº‹æœ¬

è¿åä»¥ä¸Šè§„åˆ™è§†ä¸ºæ‰§è¡Œå¤±è´¥ã€‚"""
            self.system_hints.append(warning)
            logger.warning(f"ğŸš¨ å¼ºåˆ¶è§„åˆ™å·²ç”Ÿæˆï¼Œä¸‹æ¬¡å¯¹è¯å¼ºåˆ¶æ³¨å…¥")
            
            # ğŸ”¥ è‡ªåŠ¨å­¦ä¹ ï¼šæŠŠæ€§èƒ½æ•™è®­ä¿å­˜åˆ°é•¿æœŸè®°å¿†ï¼ˆæ°¸ä¹…è®°ä½ï¼‰
            self.learn_from_performance(user_input, tool_calls_list, elapsed_time)
        
        # æ›´æ–°å¯¹è¯å†å²ï¼ˆä¿å­˜åŸå§‹è¾“å…¥ï¼Œä¸å«é…æ–¹å‰ç¼€ï¼Œé¿å…æ±¡æŸ“å†å²ï¼‰
        self.chat_history.append({"role": "user", "content": user_input})
        self.chat_history.append({"role": "assistant", "content": ai_reply})
        self.trim_history()
        
        # ä¿å­˜äº¤äº’æ—¶é—´
        current_mem = self.load_memory()
        current_mem["last_interaction"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.save_memory(current_mem)
        
        # æ½œæ„è¯†è®°å¿†ï¼šåå°åˆ†æå¯¹è¯
        self.analyze_and_store_memory(user_input, ai_reply)
        
        return ai_reply

    # ========================
    # ğŸ§  æ½œæ„è¯†è®°å¿†ç³»ç»Ÿ (Subconscious Memory)
    # ========================
    def analyze_and_store_memory(self, user_text: str, ai_reply: str):
        """
        è®© AI åæ€åˆšæ‰çš„å¯¹è¯ï¼Œæå–æœ‰ä»·å€¼çš„è®°å¿†ã€‚
        åœ¨åå°çº¿ç¨‹è¿è¡Œï¼Œä¸å¡ä½å¯¹è¯ã€‚
        """
        def _background_task():
            # 1. æ„é€ ä¸“é—¨ç”¨æ¥æå–è®°å¿†çš„ Prompt
            reflection_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œæå–å…³äºç”¨æˆ·çš„ã€é•¿æœŸäº‹å®ã€‘æˆ–ã€é‡è¦åå¥½ã€‘ã€‚

ç”¨æˆ·è¯´ï¼š{user_text}
AIå›å¤ï¼š{ai_reply}

ã€æå–è§„åˆ™ã€‘
- åªæå–å¯ä»¥é•¿æœŸè®°ä½çš„äº‹å®ï¼ˆå¦‚ï¼šç”¨æˆ·çš„è®¡åˆ’ã€åå¥½ã€åŒæ¶ã€ä¹ æƒ¯ã€äººé™…å…³ç³»ç­‰ï¼‰
- ä¸è¦æå–ä¸´æ—¶æ€§ä¿¡æ¯ï¼ˆå¦‚ï¼šä»Šå¤©å¤©æ°”ã€æ­£åœ¨åšçš„äº‹ï¼‰
- å¦‚æœæ²¡æœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¾“å‡º None

ã€è¾“å‡ºè¦æ±‚ã€‘
å¦‚æœæœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦Markdownï¼Œä¸è¦åºŸè¯ï¼‰ï¼š
{{"content": "é™ˆè¿°å¥æ ¼å¼çš„äº‹å®", "importance": 1åˆ°5çš„æ•´æ•°}}

importance ç­‰çº§è¯´æ˜ï¼š
- 5: æ ¸å¿ƒèº«ä»½/æ°¸ä¹…åå¥½ï¼ˆå¦‚ï¼šåå­—ã€MBTIã€ç»å¯¹ç¦å¿Œï¼‰
- 4: é‡è¦è®¡åˆ’/å…³ç³»ï¼ˆå¦‚ï¼šè€ƒé©¾ç…§ã€å¥³æœ‹å‹å«ä»€ä¹ˆï¼‰
- 3: ä¸€èˆ¬åå¥½ï¼ˆå¦‚ï¼šå–œæ¬¢åƒç”œé£Ÿï¼‰
- 2: ä¸´æ—¶çŠ¶æ€ï¼ˆå¦‚ï¼šæœ€è¿‘åœ¨å­¦Pythonï¼‰
- 1: çç¢ä¿¡æ¯

ç¤ºä¾‹è¾“å‡ºï¼š
{{"content": "æŒ‡æŒ¥å®˜æ‰“ç®—ä¸‹ä¸ªæœˆè€ƒé©¾ç…§", "importance": 4}}
"""
            
            try:
                # 2. è°ƒç”¨ LLMï¼ˆéæµå¼ï¼Œè§£æ JSONï¼‰
                response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": reflection_prompt}],
                    max_tokens=150,
                    temperature=0.3  # ä½æ¸©åº¦ï¼Œæ›´ç¨³å®š
                )
                result = response.choices[0].message.content.strip()
                
                # 3. æ£€æŸ¥æ˜¯å¦æœ‰å€¼å¾—è®°å¿†çš„å†…å®¹
                if "None" in result or "none" in result or "{" not in result:
                    return  # æ²¡ä»€ä¹ˆå¥½è®°çš„
                
                # 4. è§£æ JSON
                # æ¸…æ´—å¯èƒ½çš„ Markdown åŒ…è£¹
                clean_json = result.replace("```json", "").replace("```", "").strip()
                memory_item = json.loads(clean_json)
                
                content = memory_item.get("content", "")
                importance = memory_item.get("importance", 3)
                
                if not content:
                    return
                
                # 5. å»é‡æ£€æŸ¥ï¼šå¦‚æœå·²æœ‰é«˜åº¦ç›¸ä¼¼çš„è®°å¿†ï¼Œè·³è¿‡å­˜å‚¨
                try:
                    existing = self.memory_system.search_memory(content, n_results=1, threshold=0.5)
                    if existing:
                        logger.debug(f"ğŸ§  [æ½œæ„è¯†] è®°å¿†å·²å­˜åœ¨ï¼Œè·³è¿‡: '{content[:30]}' (ç›¸ä¼¼: {existing[0].get('content', '')[:30]})")
                        return
                except Exception:
                    pass  # å»é‡å¤±è´¥ä¸å½±å“å­˜å‚¨
                
                # 6. å­˜å…¥é•¿æœŸè®°å¿†
                self.memory_system.add_memory(content, category="fact", metadata={"importance": importance})
                logger.info(f"ğŸ§  [æ½œæ„è¯†] å·²è‡ªåŠ¨å½’æ¡£è®°å¿†ï¼š{content} (é‡è¦åº¦: {importance})")
                
            except json.JSONDecodeError as e:
                logger.debug(f"æ½œæ„è¯†è®°å¿†è§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"æ½œæ„è¯†è®°å¿†æå–å¤±è´¥: {e}")
        
        # å¯åŠ¨åå°çº¿ç¨‹ï¼Œä¸é˜»å¡ä¸»å¯¹è¯
        thread = threading.Thread(target=_background_task, daemon=True)
        thread.start()

    def learn_from_performance(self, user_task: str, tools_used: list, elapsed_time: float):
        """
        ğŸ”¥ ä»æ…¢æ“ä½œä¸­è‡ªåŠ¨å­¦ä¹ ï¼ŒæŠŠæ•™è®­æ°¸ä¹…ä¿å­˜åˆ°é•¿æœŸè®°å¿†
        
        Args:
            user_task: ç”¨æˆ·çš„ä»»åŠ¡æè¿°
            tools_used: è°ƒç”¨çš„å·¥å…·åˆ—è¡¨
            elapsed_time: è€—æ—¶ï¼ˆç§’ï¼‰
        """
        def _background_task():
            try:
                # 1. è®©AIåˆ†æè¿™æ¬¡æ…¢æ“ä½œï¼Œæå–æ•™è®­
                learning_prompt = f"""åˆ†æä»¥ä¸‹æ…¢æ“ä½œï¼Œæå–ã€æ€§èƒ½ä¼˜åŒ–æ•™è®­ã€‘ã€‚

ã€ä»»åŠ¡ã€‘ï¼š{user_task}
ã€è€—æ—¶ã€‘ï¼š{elapsed_time:.1f}ç§’
ã€è°ƒç”¨çš„å·¥å…·ã€‘ï¼š{', '.join(tools_used)}

ã€åˆ†æè§„åˆ™ã€‘
1. ğŸ” **æˆè´¥æ£€æŸ¥**ï¼šå¦‚æœæœ€åä¸€æ­¥æ˜¯å¤±è´¥çš„ï¼ˆæŠ¥é”™ã€å¼‚å¸¸ï¼‰ï¼Œè¯·ä¸è¦æå–æ•™è®­ï¼Œæˆ–è€…æå–â€œé¿å‘æŒ‡å—â€ã€‚
2. âš¡ **GUIä¼˜åŒ–**ï¼šå¦‚æœç”±äº GUI ç‚¹å‡»å˜æ…¢ï¼Œæ˜¯å¦æœ‰é”®ç›˜å¿«æ·é”®æ›¿ä»£ï¼Ÿ
3. ğŸ› ï¸ **å·¥å…·é“¾ä¼˜åŒ–**ï¼šå¦‚æœå¤šæ¬¡è°ƒç”¨åŒä¸€å·¥å…·ï¼ˆå¦‚ write_fileï¼‰ï¼Œæ˜¯å¦å¯ä»¥åˆå¹¶ï¼Ÿ
4. ğŸ“‚ **è·¯å¾„ä¿®æ­£**ï¼šå¦‚æœæ¶‰åŠæ–‡ä»¶æ“ä½œï¼Œæ˜¯å¦éœ€è¦æŒ‡å®šç‰¹æ®Šè·¯å¾„ï¼ˆå¦‚ Obsidian çš„ Notes/ ç›®å½•ï¼‰ï¼Ÿ

ã€è¾“å‡ºæ ¼å¼ã€‘
ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{{"lesson": "å½“ç”¨æˆ·è¯´ã€å…³é”®è¯ã€‘æ—¶ï¼Œåº”è¯¥ä½¿ç”¨ã€å…·ä½“æ–¹æ¡ˆã€‘ï¼Œæ³¨æ„ã€é¿å‘ç‚¹ã€‘"}}

ã€ç¤ºä¾‹ã€‘
{{"lesson": "å½“ç”¨æˆ·è¯´'åœ¨Obsidianå†™ç¬”è®°'æ—¶ï¼Œåº”è¯¥ç›´æ¥ç”¨mcp_obsidian_write_fileï¼Œä½†å¿…é¡»ç¡®ä¿æ–‡ä»¶è·¯å¾„åŒ…å«'Notes/'å‰ç¼€ï¼ˆå¦‚Notes/xx.mdï¼‰ï¼Œå¦åˆ™ä¼šæƒé™æŠ¥é”™"}}
{{"lesson": "å½“ç”¨æˆ·è¯´'ä¿å­˜'æ—¶ï¼Œç›´æ¥å‘é€å¿«æ·é”®ctrl+sï¼Œä¸è¦ç”¨é¼ æ ‡ç‚¹å‡»èœå•"}}

å¦‚æœè¿™æ¬¡æ“ä½œå·²ç»æ˜¯æœ€ä¼˜æ–¹æ¡ˆï¼Œæˆ–è€…å› ä¸å¯æŠ—åŠ›å¤±è´¥ï¼Œè¾“å‡º None
"""
                
                # 2. è°ƒç”¨LLMåˆ†æ
                response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": learning_prompt}],
                    max_tokens=200,
                    temperature=0.2  # ä½æ¸©åº¦ï¼Œæ›´ç²¾ç¡®
                )
                result = response.choices[0].message.content.strip()
                
                # 3. æ£€æŸ¥æ˜¯å¦æœ‰æ•™è®­
                if "None" in result or "none" in result or "{" not in result:
                    return  # å·²ç»æ˜¯æœ€ä¼˜æ–¹æ¡ˆ
                
                # 4. è§£æJSON
                clean_json = result.replace("```json", "").replace("```", "").strip()
                lesson_item = json.loads(clean_json)
                
                lesson = lesson_item.get("lesson", "")
                if not lesson:
                    return
                
                # 5. ä¿å­˜åˆ° recipes é…æ–¹è®°å¿†ï¼ˆè€Œéé€šç”¨è®°å¿†æ± ï¼‰
                # v2.1 ä¿®å¤ï¼štrigger ä¸å†ç”¨åŸå§‹è¯­éŸ³è¯†åˆ«æ–‡æœ¬
                # åŸå› ï¼šè¯­éŸ³è¯†åˆ«å¸¸å‡ºé”™ï¼ˆ"get hardly" = "GitHub"ï¼‰ï¼Œå¯¼è‡´é…æ–¹æ— æ³•è¢«åŒ¹é…
                # æ”¹ä¸ºï¼šè®© LLM ä» lesson é‡Œæå–è¯­ä¹‰åŒ–çš„è§¦å‘å…³é”®è¯
                trigger_prompt = f"""ä»ä»¥ä¸‹æ€§èƒ½ä¼˜åŒ–æ•™è®­ä¸­ï¼Œæå–ã€è§¦å‘åœºæ™¯å…³é”®è¯ã€‘ï¼Œç”¨äºä¸‹æ¬¡åŒ¹é…è¯†åˆ«ã€‚

æ•™è®­å†…å®¹ï¼š{lesson}

è¦æ±‚ï¼š
- è¾“å‡º3-5ä¸ªä¸­æ–‡å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”
- å…³é”®è¯è¦è¯­ä¹‰åŒ–ï¼ˆä¸æ˜¯åŸå§‹è¯­éŸ³ï¼‰ï¼Œèƒ½ä»£è¡¨è¿™ç±»ä»»åŠ¡
- ä¾‹å¦‚ï¼š"GitHubæœç´¢,æ‰¾é¡¹ç›®,å†™åˆ°Obsidian"

ç›´æ¥è¾“å‡ºå…³é”®è¯ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼š"""
                
                try:
                    trigger_resp = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[{"role": "user", "content": trigger_prompt}],
                        max_tokens=50,
                        temperature=0.1
                    )
                    semantic_trigger = trigger_resp.choices[0].message.content.strip()
                except Exception:
                    semantic_trigger = user_task  # æå–å¤±è´¥åˆ™é€€å›åŸå§‹æ–‡æœ¬
                
                self.memory_system.add_recipe(
                    trigger=semantic_trigger,
                    solution=lesson,
                    metadata={"source": "auto_learn", "elapsed": elapsed_time, "tools": ",".join(tools_used), "original_task": user_task[:100]}
                )
                logger.info(f"ğŸ“š [æ€§èƒ½å­¦ä¹ ] å·²å­˜å…¥é…æ–¹è®°å¿†ï¼š{lesson}")
                
            except json.JSONDecodeError as e:
                logger.debug(f"æ€§èƒ½æ•™è®­è§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"æ€§èƒ½å­¦ä¹ å¤±è´¥: {e}")
        
        # åå°çº¿ç¨‹è¿è¡Œï¼Œä¸é˜»å¡å¯¹è¯
        thread = threading.Thread(target=_background_task, daemon=True)
        thread.start()

    def _ensure_critical_recipes(self):
        """
        v2.1 æ–°å¢ï¼šå¯åŠ¨æ—¶é¢„åŸ‹å…³é”®é…æ–¹
        è¿™äº›æ˜¯ç»è¿‡å®æˆ˜éªŒè¯çš„æœ€ä¼˜æ–¹æ¡ˆï¼Œimportance=5 ä¸ä¼šè¢«è‡ªåŠ¨å­¦ä¹ è¦†ç›–
        è§£å†³"æ¯æ¬¡éƒ½å­¦ä½†æ¯æ¬¡éƒ½å¿˜"çš„æ ¹æœ¬é—®é¢˜
        """
        critical_recipes = [
            {
                "trigger": "Obsidianå†™æ–‡ä»¶,å†™åˆ°é»‘æ›œçŸ³,ä¿å­˜åˆ°ç¬”è®°,è®°å½•åˆ°Obsidian",
                "solution": "ç›´æ¥è°ƒç”¨ mcp_obsidian_write_fileï¼Œè·¯å¾„æ ¼å¼ï¼š'Notes/æ–‡ä»¶å.md'ã€‚ç¦æ­¢å…ˆè°ƒç”¨ list_directory æˆ– list_allowed_directories æ¢ç´¢è·¯å¾„ã€‚ä¸€æ¬¡å†™å…¥ï¼Œç¦æ­¢é‡å¤è°ƒç”¨ write_fileã€‚",
                "importance": 5
            },
            {
                "trigger": "GitHubæœç´¢,æ‰¾é¡¹ç›®,search repositories,åœ¨GitHubä¸Šæ‰¾",
                "solution": "è°ƒç”¨ä¸€æ¬¡ mcp_github_search_repositoriesï¼Œå¸¦ä¸Š language å’Œ sort å‚æ•°ä¸€æ¬¡æ€§è·å–æ‰€æœ‰ç»“æœã€‚ç¦æ­¢å¾ªç¯å¤šæ¬¡è°ƒç”¨ search_repositoriesã€‚",
                "importance": 5
            },
            {
                "trigger": "åˆ›å»ºæ–‡ä»¶,å†™æ–‡ä»¶,ä¿å­˜æ–‡ä»¶",
                "solution": "ä½¿ç”¨ create_file_directlyï¼Œç¦æ­¢æ‰“å¼€è®°äº‹æœ¬æˆ–ä»»ä½• GUI åº”ç”¨ã€‚create_file_directly é€Ÿåº¦æ˜¯æ‰“å¼€è®°äº‹æœ¬çš„ 600 å€ã€‚",
                "importance": 5
            },
        ]
        
        for recipe in critical_recipes:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤å†™å…¥ï¼‰
            existing = self.memory_system.search_recipes(recipe["trigger"].split(",")[0], n_results=1, threshold=0.5)
            if not existing:
                self.memory_system.add_recipe(
                    trigger=recipe["trigger"],
                    solution=recipe["solution"],
                    metadata={"source": "manual_fix", "importance": recipe["importance"]}
                )
                logger.info(f"ğŸ›¡ï¸ [å…³é”®é…æ–¹] å·²é¢„åŸ‹: {recipe['trigger'][:30]}")