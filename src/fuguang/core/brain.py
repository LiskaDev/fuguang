
import json
import os
import sys
import time
import datetime
import logging
import httpx
import threading
from openai import OpenAI
from .config import ConfigManager
from .mouth import Mouth
from .. import memory as fuguang_memory

logger = logging.getLogger("Fuguang")

class Brain:
    """
    æ€è€ƒä¸è®°å¿†è§’è‰²
    èŒè´£ï¼šAI å®¢æˆ·ç«¯ã€èŠå¤©å†å²ã€è®°å¿†ã€System Prompt
    """

    MAX_HISTORY = 20
    QUICK_LOCAL_TRIGGERS = ["å‡ ç‚¹", "æ—¶é—´", "å‡ å·", "æ—¥æœŸ", "ç”µé‡", "çŠ¶æ€"]

    def __init__(self, config: ConfigManager, mouth: Mouth):
        self.config = config
        self.mouth = mouth

        # AI å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=config.DEEPSEEK_API_KEY,
            base_url=config.DEEPSEEK_BASE_URL,
            timeout=httpx.Timeout(120.0, connect=10.0)
        )

        # é•¿æœŸè®°å¿†ç³»ç»Ÿ
        self.memory_system = fuguang_memory.MemorySystem()

        # çŸ­æœŸå¯¹è¯å†å²
        self.chat_history = []

        # çŠ¶æ€
        self.IS_CREATION_MODE = False
        
        # ğŸ”¥ æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
        self.performance_log = []  # è®°å½•æ¯æ¬¡ä»»åŠ¡çš„æ€§èƒ½æ•°æ®
        self.system_hints = []  # å­˜å‚¨ç»™AIçš„ç³»ç»Ÿæç¤ºï¼ˆå¦‚æ€§èƒ½è­¦å‘Šï¼‰

    def load_memory(self) -> dict:
        """åŠ è½½çŸ­æœŸè®°å¿†"""
        if not self.config.MEMORY_FILE.exists():
            return {"user_profile": {}, "short_term_summary": "æš‚æ— è®°å½•"}
        try:
            with open(self.config.MEMORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {"user_profile": {}, "short_term_summary": "æ–‡ä»¶æŸå"}

    def save_memory(self, memory_data: dict):
        """ä¿å­˜çŸ­æœŸè®°å¿†"""
        try:
            with open(self.config.MEMORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(memory_data, f, ensure_ascii=False, indent=4)
            logger.info("ğŸ’¾ è®°å¿†å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"è®°å¿†ä¿å­˜å¤±è´¥: {e}")

    def get_system_prompt(self, dynamic_context: dict = None) -> str:
        """
        ç”ŸæˆåŠ¨æ€ System Prompt
        
        Args:
            dynamic_context: å®æ—¶æ„ŸçŸ¥æ•°æ®ï¼ŒåŒ…å«:
                - app: å½“å‰æ´»åŠ¨çª—å£æ ‡é¢˜
                - clipboard: å‰ªè´´æ¿å†…å®¹
                - user_present: ç”¨æˆ·æ˜¯å¦åœ¨åº§ï¼ˆå¯é€‰ï¼‰
        """
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][datetime.datetime.now().weekday()]
        current_date = f"{datetime.datetime.now().strftime('%Y-%m-%d')} {weekday}"
        mode_status = "ğŸ”“å·²è§£é”" if self.IS_CREATION_MODE else "ğŸ”’å·²é”å®š"

        memory = self.load_memory()
        user_profile = json.dumps(memory.get("user_profile", {}), ensure_ascii=False)
        summary = memory.get("short_term_summary", "æš‚æ— ")

        # æ„å»ºæ„ŸçŸ¥ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†ï¼‰
        perception_section = ""
        if dynamic_context:
            app_name = dynamic_context.get("app", "æœªçŸ¥")
            clipboard = dynamic_context.get("clipboard", "æ— ")
            user_present = dynamic_context.get("user_present", None)
            visual_status = ""
            if user_present is not None:
                visual_status = "æŒ‡æŒ¥å®˜åœ¨åº§ä½ä¸Š" if user_present else "åº§ä½æ— äºº"
            
            perception_section = f"""

ã€å®æ—¶æ„ŸçŸ¥çŠ¶æ€ã€‘
- ç”¨æˆ·æ­£åœ¨æ“ä½œ: {app_name}
- å‰ªè´´æ¿å†…å®¹: {clipboard}
{f'- è§†è§‰çŠ¶æ€: {visual_status}' if visual_status else ''}
ï¼ˆå½“ç”¨æˆ·é—®"è¿™ä¸ª"ã€"è¿™æ®µä»£ç "ã€"å¸®æˆ‘çœ‹çœ‹"æ—¶ï¼ŒæŒ‡çš„å°±æ˜¯å‰ªè´´æ¿å†…å®¹ï¼›å½“ç”¨æˆ·é—®"æˆ‘åœ¨å¹²å˜›"æ—¶è¯·æ ¹æ®å½“å‰çª—å£å›ç­”ï¼‰
"""

        try:
            with open(self.config.SYSTEM_PROMPT_FILE, "r", encoding="utf-8") as f:
                template = f.read()
            prompt = template.format(
                current_time=current_time,
                current_date=current_date,
                mode_status=mode_status,
                history_summary=f"ã€ç”¨æˆ·æ¡£æ¡ˆã€‘{user_profile}\nã€ä¸Šæ¬¡è¯é¢˜æ‘˜è¦ã€‘{summary}"
            )
            # è¿½åŠ æ„ŸçŸ¥ä¿¡æ¯
            return prompt + perception_section
        except Exception:
            return f"ä½ æ˜¯æ²ˆæ‰¶å…‰ï¼Œè¯´è¯ç®€æ´ã€‚[Neutral]{perception_section}"

    def trim_history(self):
        """ä¿®å‰ªå¯¹è¯å†å²ï¼Œé˜²æ­¢è¿‡é•¿"""
        if len(self.chat_history) <= self.MAX_HISTORY * 2:
            return

        target_len = self.MAX_HISTORY * 2 - 10
        start_idx = max(0, len(self.chat_history) - target_len)  # [ä¿®å¤L-5] é˜²æ­¢è´Ÿç´¢å¼•
        for i in range(start_idx, len(self.chat_history)):
            if i >= 0 and self.chat_history[i]["role"] == "user":
                self.chat_history = self.chat_history[i:]
                return

        self.chat_history = self.chat_history[-(self.MAX_HISTORY * 2):]

    def should_auto_respond(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨å“åº”æœ¬åœ°æŒ‡ä»¤"""
        return any(trigger in text for trigger in self.QUICK_LOCAL_TRIGGERS)

    def summarize_and_exit(self):
        """æ•´ç†è®°å¿†å¹¶é€€å‡º"""
        logger.info("æ­£åœ¨æ•´ç†ä»Šæ—¥è®°å¿†...")
        self.mouth.speak("æŒ‡æŒ¥å®˜ï¼Œæ­£åœ¨åŒæ­¥è®°å¿†æ•°æ®...")

        if len(self.chat_history) < 2:
            self.mouth.speak("æ™šå®‰ã€‚")
            sys.exit(0)  # [ä¿®å¤H-1] ä½¿ç”¨ sys.exit æ›¿ä»£ os._exitï¼Œå…è®¸ finally/atexit æ¸…ç†

        conversation_text = ""
        for msg in self.chat_history:
            role = "é˜¿é‘«" if msg["role"] == "user" else "æ‰¶å…‰"
            conversation_text += f"{role}: {msg['content']}\n"

        try:
            summary_prompt = [
                {"role": "system", "content": "è¯·ç®€è¦æ€»ç»“ä»¥ä¸‹å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ã€‚100å­—ä»¥å†…ã€‚"},
                {"role": "user", "content": conversation_text}
            ]
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=summary_prompt,
                max_tokens=200,
                temperature=0.5
            )
            new_summary = response.choices[0].message.content
            logger.info(f"ğŸ“ ä»Šæ—¥æ—¥è®°: {new_summary}")

            mem = self.load_memory()
            old = mem.get("short_term_summary", "")
            mem["short_term_summary"] = f"{new_summary} | (æ—§: {old[:50]}...)"
            self.save_memory(mem)

        except Exception as e:
            logger.error(f"æ€»ç»“å¤±è´¥: {e}")

        self.mouth.speak("è®°å¿†åŒæ­¥å®Œæˆï¼Œæ™šå®‰ã€‚")
        time.sleep(1)
        sys.exit(0)  # [ä¿®å¤H-1] ä½¿ç”¨ sys.exit æ›¿ä»£ os._exit

    # ========================
    # ğŸ§  æ ¸å¿ƒå¯¹è¯æ–¹æ³• (Function Calling)
    # ========================
    def chat(self, user_input: str, system_content: str, tools_schema: list, tool_executor) -> str:
        """
        æ ¸å¿ƒå¯¹è¯æ–¹æ³•ï¼šæ”¯æŒ Function Calling (å·¥å…·è°ƒç”¨)
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            system_content: å®Œæ•´çš„ System Promptï¼ˆåŒ…å«è®°å¿†ï¼‰
            tools_schema: å·¥å…·å®šä¹‰åˆ—è¡¨
            tool_executor: å·¥å…·æ‰§è¡Œå‡½æ•° (func_name, func_args) -> result
            
        Returns:
            AI çš„æœ€ç»ˆå›å¤æ–‡æœ¬
        """
        # ğŸ”¥ æ€§èƒ½ç›‘æ§ï¼šè®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        tool_calls_list = []  # è®°å½•æœ¬æ¬¡è°ƒç”¨çš„æ‰€æœ‰å·¥å…·
        
        # æ³¨å…¥ç³»ç»Ÿæç¤ºï¼ˆå¦‚æ€§èƒ½è­¦å‘Šï¼‰
        if self.system_hints:
            hints_text = "\n".join(self.system_hints)
            system_content += f"\n\nã€âš ï¸ ç³»ç»Ÿæç¤ºã€‘\n{hints_text}\n"
            self.system_hints.clear()  # æ¸…ç©ºæç¤ºï¼Œåªæ˜¾ç¤ºä¸€æ¬¡
        
        messages = [{"role": "system", "content": system_content}]
        messages.extend(self.chat_history)
        messages.append({"role": "user", "content": user_input})
        
        # [è°ƒæ•´] å¢åŠ æ€è€ƒè½®æ¬¡ä¸Šé™ï¼Œä»¥æ”¯æŒå¤æ‚çš„è¿ç»­ä»»åŠ¡ (å¦‚: æ‰“å¼€ç½‘é¡µ -> æˆªå›¾ -> åˆ†æ -> æ€»ç»“)
        max_iterations = 15
        iteration = 0
        ai_reply = ""
        
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"ğŸ¤– AIæ€è€ƒè½®æ¬¡: {iteration}")
            
            # è°ƒç”¨ DeepSeek
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                tools=tools_schema,
                tool_choice="auto",
                stream=False,
                temperature=0.8,
                max_tokens=4096
            )
            
            message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if message.tool_calls:
                logger.info(f"ğŸ”§ AIè¯·æ±‚ä½¿ç”¨å·¥å…·: {len(message.tool_calls)} ä¸ª")
                
                # æŠŠ AI çš„å·¥å…·è°ƒç”¨æ„å›¾åŠ å…¥å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
                for tool_call in message.tool_calls:
                    func_name = tool_call.function.name
                    
                    # [ä¿®å¤C-2] é˜²æ­¢ API è¿”å›ç•¸å½¢ JSON å¯¼è‡´å´©æºƒ
                    try:
                        func_args = json.loads(tool_call.function.arguments)
                    except (json.JSONDecodeError, TypeError) as e:
                        logger.error(f"å·¥å…·å‚æ•°è§£æå¤±è´¥: {func_name}, åŸå§‹å‚æ•°: {tool_call.function.arguments}, é”™è¯¯: {e}")
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": f"å‚æ•°è§£æé”™è¯¯: {e}"
                        })
                        continue
                    
                    logger.info(f"ğŸ“ è°ƒç”¨å·¥å…·: {func_name}")
                    tool_calls_list.append(func_name)  # ğŸ”¥ è®°å½•å·¥å…·è°ƒç”¨
                    result = tool_executor(func_name, func_args)
                    
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
                
                # ç»§ç»­ä¸‹ä¸€è½®ï¼Œè®© AI æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆå›å¤
                continue
            
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è·å–å›å¤
                ai_reply = message.content
                break
        
        else:
            # è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
            ai_reply = "æŒ‡æŒ¥å®˜ï¼Œè¿™ä¸ªé—®é¢˜æœ‰ç‚¹å¤æ‚ï¼Œæˆ‘éœ€è¦æ›´å¤šæ—¶é—´æ€è€ƒ..."
        
        # ğŸ”¥ æ€§èƒ½ç›‘æ§ï¼šè®°å½•ç»“æŸæ—¶é—´å’Œç»Ÿè®¡æ•°æ®
        elapsed_time = time.time() - start_time
        tool_count = len(tool_calls_list)
        
        # è®°å½•åˆ°æ€§èƒ½æ—¥å¿—ï¼ˆä¿ç•™æœ€è¿‘20æ¡ï¼‰
        self.performance_log.append({
            "task": user_input[:50],  # æˆªå–å‰50å­—ç¬¦
            "time": round(elapsed_time, 2),
            "steps": tool_count,
            "tools_used": tool_calls_list,
            "timestamp": datetime.datetime.now().strftime("%H:%M:%S")
        })
        if len(self.performance_log) > 20:
            self.performance_log.pop(0)  # ç§»é™¤æœ€æ—§çš„è®°å½•
        
        logger.info(f"â±ï¸ [æ€§èƒ½] æœ¬æ¬¡ä»»åŠ¡è€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œè°ƒç”¨å·¥å…·: {tool_count}ä¸ª")
        
        # ğŸ”¥ æ€§èƒ½è­¦å‘Šï¼šå¦‚æœå¤ªæ…¢æˆ–è°ƒç”¨å¤ªå¤šå·¥å…·ï¼Œç»™AIå‘é€ä¼˜åŒ–å»ºè®®
        if elapsed_time > 10 and tool_count > 3:
            warning = f"""âš ï¸ æ€§èƒ½è­¦å‘Šï¼šä¸Šä¸€ä¸ªä»»åŠ¡è€—æ—¶ {elapsed_time:.1f}ç§’ï¼Œè°ƒç”¨äº† {tool_count} ä¸ªå·¥å…·ã€‚

è¯·åæ€ï¼š
- æ˜¯å¦æœ‰æ›´å¿«çš„æ–¹æ³•ï¼Ÿï¼ˆå¦‚ç”¨ create_file_directly ä»£æ›¿æ‰“å¼€è®°äº‹æœ¬ï¼‰
- æ˜¯å¦å¯ä»¥ç”¨å¿«æ·é”®ä»£æ›¿ç‚¹å‡»èœå•ï¼Ÿï¼ˆå¦‚ Ctrl+S ä¿å­˜ï¼‰
- æ˜¯å¦å¯ä»¥åˆå¹¶å¤šä¸ªæ“ä½œä¸ºä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼Ÿ

è®°ä½ï¼šç”¨æˆ·è¦çš„æ˜¯ç»“æœï¼Œä¸æ˜¯è¿‡ç¨‹ã€‚ä¼˜å…ˆä½¿ç”¨ã€å·¥å…·ä¼˜å…ˆçº§1-2ã€‘çš„æ–¹æ³•ã€‚

æœ€è¿‘è°ƒç”¨çš„å·¥å…·ï¼š{', '.join(tool_calls_list[-5:])}"""
            self.system_hints.append(warning)  # ä¸‹æ¬¡å¯¹è¯æ—¶è‡ªåŠ¨æ³¨å…¥
            logger.warning(f"ğŸ¢ æ€§èƒ½è­¦å‘Šå·²ç”Ÿæˆï¼Œå°†åœ¨ä¸‹æ¬¡å¯¹è¯æ—¶æé†’AIä¼˜åŒ–")
        
        # æ›´æ–°å¯¹è¯å†å²
        self.chat_history.append({"role": "user", "content": user_input})
        self.chat_history.append({"role": "assistant", "content": ai_reply})
        self.trim_history()
        
        # ä¿å­˜äº¤äº’æ—¶é—´
        current_mem = self.load_memory()
        current_mem["last_interaction"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.save_memory(current_mem)
        
        # æ½œæ„è¯†è®°å¿†ï¼šåå°åˆ†æå¯¹è¯
        self.analyze_and_store_memory(user_input, ai_reply)
        
        return ai_reply

    # ========================
    # ğŸ§  æ½œæ„è¯†è®°å¿†ç³»ç»Ÿ (Subconscious Memory)
    # ========================
    def analyze_and_store_memory(self, user_text: str, ai_reply: str):
        """
        è®© AI åæ€åˆšæ‰çš„å¯¹è¯ï¼Œæå–æœ‰ä»·å€¼çš„è®°å¿†ã€‚
        åœ¨åå°çº¿ç¨‹è¿è¡Œï¼Œä¸å¡ä½å¯¹è¯ã€‚
        """
        def _background_task():
            # 1. æ„é€ ä¸“é—¨ç”¨æ¥æå–è®°å¿†çš„ Prompt
            reflection_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œæå–å…³äºç”¨æˆ·çš„ã€é•¿æœŸäº‹å®ã€‘æˆ–ã€é‡è¦åå¥½ã€‘ã€‚

ç”¨æˆ·è¯´ï¼š{user_text}
AIå›å¤ï¼š{ai_reply}

ã€æå–è§„åˆ™ã€‘
- åªæå–å¯ä»¥é•¿æœŸè®°ä½çš„äº‹å®ï¼ˆå¦‚ï¼šç”¨æˆ·çš„è®¡åˆ’ã€åå¥½ã€åŒæ¶ã€ä¹ æƒ¯ã€äººé™…å…³ç³»ç­‰ï¼‰
- ä¸è¦æå–ä¸´æ—¶æ€§ä¿¡æ¯ï¼ˆå¦‚ï¼šä»Šå¤©å¤©æ°”ã€æ­£åœ¨åšçš„äº‹ï¼‰
- å¦‚æœæ²¡æœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¾“å‡º None

ã€è¾“å‡ºè¦æ±‚ã€‘
å¦‚æœæœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦Markdownï¼Œä¸è¦åºŸè¯ï¼‰ï¼š
{{"content": "é™ˆè¿°å¥æ ¼å¼çš„äº‹å®", "importance": 1åˆ°5çš„æ•´æ•°}}

importance ç­‰çº§è¯´æ˜ï¼š
- 5: æ ¸å¿ƒèº«ä»½/æ°¸ä¹…åå¥½ï¼ˆå¦‚ï¼šåå­—ã€MBTIã€ç»å¯¹ç¦å¿Œï¼‰
- 4: é‡è¦è®¡åˆ’/å…³ç³»ï¼ˆå¦‚ï¼šè€ƒé©¾ç…§ã€å¥³æœ‹å‹å«ä»€ä¹ˆï¼‰
- 3: ä¸€èˆ¬åå¥½ï¼ˆå¦‚ï¼šå–œæ¬¢åƒç”œé£Ÿï¼‰
- 2: ä¸´æ—¶çŠ¶æ€ï¼ˆå¦‚ï¼šæœ€è¿‘åœ¨å­¦Pythonï¼‰
- 1: çç¢ä¿¡æ¯

ç¤ºä¾‹è¾“å‡ºï¼š
{{"content": "æŒ‡æŒ¥å®˜æ‰“ç®—ä¸‹ä¸ªæœˆè€ƒé©¾ç…§", "importance": 4}}
"""
            
            try:
                # 2. è°ƒç”¨ LLMï¼ˆéæµå¼ï¼Œè§£æ JSONï¼‰
                response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": reflection_prompt}],
                    max_tokens=150,
                    temperature=0.3  # ä½æ¸©åº¦ï¼Œæ›´ç¨³å®š
                )
                result = response.choices[0].message.content.strip()
                
                # 3. æ£€æŸ¥æ˜¯å¦æœ‰å€¼å¾—è®°å¿†çš„å†…å®¹
                if "None" in result or "none" in result or "{" not in result:
                    return  # æ²¡ä»€ä¹ˆå¥½è®°çš„
                
                # 4. è§£æ JSON
                # æ¸…æ´—å¯èƒ½çš„ Markdown åŒ…è£¹
                clean_json = result.replace("```json", "").replace("```", "").strip()
                memory_item = json.loads(clean_json)
                
                content = memory_item.get("content", "")
                importance = memory_item.get("importance", 3)
                
                if not content:
                    return
                
                # 5. å­˜å…¥é•¿æœŸè®°å¿†
                self.memory_system.add_memory(content, importance)
                logger.info(f"ğŸ§  [æ½œæ„è¯†] å·²è‡ªåŠ¨å½’æ¡£è®°å¿†ï¼š{content} (é‡è¦åº¦: {importance})")
                
            except json.JSONDecodeError as e:
                logger.debug(f"æ½œæ„è¯†è®°å¿†è§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"æ½œæ„è¯†è®°å¿†æå–å¤±è´¥: {e}")
        
        # å¯åŠ¨åå°çº¿ç¨‹ï¼Œä¸é˜»å¡ä¸»å¯¹è¯
        thread = threading.Thread(target=_background_task, daemon=True)
        thread.start()
