import json
import os
import sys
import time
import datetime
import logging
import httpx
import threading
from openai import OpenAI, APITimeoutError, APIConnectionError, RateLimitError, APIStatusError
from .config import ConfigManager
from .mouth import Mouth
from .memory import MemoryBank  # [Migration] Use new ChromaDB memory

logger = logging.getLogger("Fuguang")

class Brain:
    """
    æ€è€ƒä¸è®°å¿†è§’è‰²
    èŒè´£ï¼šAI å®¢æˆ·ç«¯ã€èŠå¤©å†å²ã€è®°å¿†ã€System Prompt
    """

    MAX_HISTORY = 20
    QUICK_LOCAL_TRIGGERS = ["å‡ ç‚¹", "æ—¶é—´", "å‡ å·", "æ—¥æœŸ", "ç”µé‡", "çŠ¶æ€"]

    def __init__(self, config: ConfigManager, mouth: Mouth):
        self.config = config
        self.mouth = mouth

        # AI å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=config.DEEPSEEK_API_KEY,
            base_url=config.DEEPSEEK_BASE_URL,
            timeout=httpx.Timeout(120.0, connect=10.0)
        )

        # [Migration] é•¿æœŸè®°å¿†ç³»ç»Ÿ (ChromaDB)
        self.memory_system = MemoryBank(
            persist_dir=str(self.config.PROJECT_ROOT / "data" / "memory_db"),
            obsidian_vault_path=getattr(self.config, 'OBSIDIAN_VAULT_PATH', '')
        )

        # çŸ­æœŸå¯¹è¯å†å²
        self.chat_history = []

        # çŠ¶æ€
        self.IS_CREATION_MODE = False

        # ğŸ”’ çº¿ç¨‹å®‰å…¨é”ï¼ˆä¿®å¤é£é™©1ï¼šChromaDB å¤šçº¿ç¨‹å†™å…¥å¯èƒ½é”æ­»ï¼‰
        # æ‰€æœ‰åå°çº¿ç¨‹å†™å…¥ memory_system å‰å¿…é¡»å…ˆè·å–æ­¤é”
        self._memory_lock = threading.Lock()

        # ğŸ”¥ æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
        self.performance_log = []  # è®°å½•æ¯æ¬¡ä»»åŠ¡çš„æ€§èƒ½æ•°æ®
        self.system_hints = []     # å­˜å‚¨ç»™AIçš„ç³»ç»Ÿæç¤ºï¼ˆå¦‚æ€§èƒ½è­¦å‘Šï¼‰

    def load_memory(self) -> dict:
        """åŠ è½½çŸ­æœŸè®°å¿†"""
        if not self.config.MEMORY_FILE.exists():
            return {"user_profile": {}, "short_term_summary": "æš‚æ— è®°å½•"}
        try:
            with open(self.config.MEMORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {"user_profile": {}, "short_term_summary": "æ–‡ä»¶æŸå"}

    def save_memory(self, memory_data: dict):
        """ä¿å­˜çŸ­æœŸè®°å¿†"""
        try:
            with open(self.config.MEMORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(memory_data, f, ensure_ascii=False, indent=4)
            logger.info("ğŸ’¾ è®°å¿†å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"è®°å¿†ä¿å­˜å¤±è´¥: {e}")

    def get_system_prompt(self, dynamic_context: dict = None) -> str:
        """
        ç”ŸæˆåŠ¨æ€ System Prompt
        
        Args:
            dynamic_context: å®æ—¶æ„ŸçŸ¥æ•°æ®ï¼ŒåŒ…å«:
                - app: å½“å‰æ´»åŠ¨çª—å£æ ‡é¢˜
                - clipboard: å‰ªè´´æ¿å†…å®¹
                - user_present: ç”¨æˆ·æ˜¯å¦åœ¨åº§ï¼ˆå¯é€‰ï¼‰
        """
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][datetime.datetime.now().weekday()]
        current_date = f"{datetime.datetime.now().strftime('%Y-%m-%d')} {weekday}"
        mode_status = "ğŸ”“å·²è§£é”" if self.IS_CREATION_MODE else "ğŸ”’å·²é”å®š"

        memory = self.load_memory()
        user_profile = json.dumps(memory.get("user_profile", {}), ensure_ascii=False)
        summary = memory.get("short_term_summary", "æš‚æ— ")

        # æ„å»ºæ„ŸçŸ¥ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†ï¼‰
        perception_section = ""
        if dynamic_context:
            app_name = dynamic_context.get("app", "æœªçŸ¥")
            clipboard = dynamic_context.get("clipboard", "æ— ")
            user_present = dynamic_context.get("user_present", None)
            visual_status = ""
            if user_present is not None:
                visual_status = "æŒ‡æŒ¥å®˜åœ¨åº§ä½ä¸Š" if user_present else "åº§ä½æ— äºº"
            
            perception_section = f"""

ã€å®æ—¶æ„ŸçŸ¥çŠ¶æ€ã€‘
- ç”¨æˆ·æ­£åœ¨æ“ä½œ: {app_name}
- å‰ªè´´æ¿å†…å®¹: {clipboard}
{f'- è§†è§‰çŠ¶æ€: {visual_status}' if visual_status else ''}
ï¼ˆå½“ç”¨æˆ·é—®"è¿™ä¸ª"ã€"è¿™æ®µä»£ç "ã€"å¸®æˆ‘çœ‹çœ‹"æ—¶ï¼ŒæŒ‡çš„å°±æ˜¯å‰ªè´´æ¿å†…å®¹ï¼›å½“ç”¨æˆ·é—®"æˆ‘åœ¨å¹²å˜›"æ—¶è¯·æ ¹æ®å½“å‰çª—å£å›ç­”ï¼‰
"""

        try:
            with open(self.config.SYSTEM_PROMPT_FILE, "r", encoding="utf-8") as f:
                template = f.read()
            # ä½¿ç”¨ str.replace è€Œé str.formatï¼Œé¿å… system_prompt.txt ä¸­çš„
            # JSON ç¤ºä¾‹ï¼ˆå¦‚ {"name": "RedSphere"}ï¼‰è§¦å‘ KeyError
            prompt = template.replace("{current_time}", current_time)
            prompt = prompt.replace("{current_date}", current_date)
            prompt = prompt.replace("{mode_status}", mode_status)
            prompt = prompt.replace("{history_summary}", f"ã€ç”¨æˆ·æ¡£æ¡ˆã€‘{user_profile}\nã€ä¸Šæ¬¡è¯é¢˜æ‘˜è¦ã€‘{summary}")
            # è¿½åŠ æ„ŸçŸ¥ä¿¡æ¯
            return prompt + perception_section
        except Exception:
            return f"ä½ æ˜¯æ²ˆæ‰¶å…‰ï¼Œè¯´è¯ç®€æ´ã€‚[Neutral]{perception_section}"

    def trim_history(self):
        """ä¿®å‰ªå¯¹è¯å†å²ï¼Œé˜²æ­¢è¿‡é•¿"""
        if len(self.chat_history) <= self.MAX_HISTORY * 2:
            return

        target_len = self.MAX_HISTORY * 2 - 10
        start_idx = max(0, len(self.chat_history) - target_len)  # [ä¿®å¤L-5] é˜²æ­¢è´Ÿç´¢å¼•
        for i in range(start_idx, len(self.chat_history)):
            if i >= 0 and self.chat_history[i]["role"] == "user":
                self.chat_history = self.chat_history[i:]
                return

        self.chat_history = self.chat_history[-(self.MAX_HISTORY * 2):]

    def should_auto_respond(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨å“åº”æœ¬åœ°æŒ‡ä»¤"""
        return any(trigger in text for trigger in self.QUICK_LOCAL_TRIGGERS)

    def summarize_and_exit(self):
        """æ•´ç†è®°å¿†å¹¶é€€å‡º"""
        logger.info("æ­£åœ¨æ•´ç†ä»Šæ—¥è®°å¿†...")
        self.mouth.speak("æŒ‡æŒ¥å®˜ï¼Œæ­£åœ¨åŒæ­¥è®°å¿†æ•°æ®...")

        if len(self.chat_history) < 2:
            self.mouth.speak("æ™šå®‰ã€‚")
            sys.exit(0)  # [ä¿®å¤H-1] ä½¿ç”¨ sys.exit æ›¿ä»£ os._exitï¼Œå…è®¸ finally/atexit æ¸…ç†

        conversation_text = ""
        for msg in self.chat_history:
            role = "é˜¿é‘«" if msg["role"] == "user" else "æ‰¶å…‰"
            conversation_text += f"{role}: {msg['content']}\n"

        try:
            summary_prompt = [
                {"role": "system", "content": "è¯·ç®€è¦æ€»ç»“ä»¥ä¸‹å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ã€‚100å­—ä»¥å†…ã€‚"},
                {"role": "user", "content": conversation_text}
            ]
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=summary_prompt,
                max_tokens=200,
                temperature=0.5
            )
            new_summary = response.choices[0].message.content
            logger.info(f"ğŸ“ ä»Šæ—¥æ—¥è®°: {new_summary}")

            mem = self.load_memory()
            old = mem.get("short_term_summary", "")
            mem["short_term_summary"] = f"{new_summary} | (æ—§: {old[:50]}...)"
            self.save_memory(mem)

        except Exception as e:
            logger.error(f"æ€»ç»“å¤±è´¥: {e}")

        self.mouth.speak("è®°å¿†åŒæ­¥å®Œæˆï¼Œæ™šå®‰ã€‚")
        time.sleep(1)
        sys.exit(0)  # [ä¿®å¤H-1] ä½¿ç”¨ sys.exit æ›¿ä»£ os._exit

    # ========================
    # ğŸ§  æ ¸å¿ƒå¯¹è¯æ–¹æ³• (Function Calling)
    # ========================
    def chat(self, user_input: str, system_content: str, tools_schema: list, tool_executor, progress_callback=None, cancel_event=None) -> str:
        """
        æ ¸å¿ƒå¯¹è¯æ–¹æ³•ï¼šæ”¯æŒ Function Calling (å·¥å…·è°ƒç”¨)
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            system_content: å®Œæ•´çš„ System Promptï¼ˆåŒ…å«è®°å¿†ï¼‰
            tools_schema: å·¥å…·å®šä¹‰åˆ—è¡¨
            tool_executor: å·¥å…·æ‰§è¡Œå‡½æ•° (func_name, func_args) -> result
            progress_callback: å¯é€‰çš„è¿›åº¦å›è°ƒ (dict) -> Noneï¼Œç”¨äºå®æ—¶é€šçŸ¥è°ƒç”¨çŠ¶æ€
            cancel_event: å¯é€‰çš„ threading.Eventï¼Œå¤–éƒ¨è®¾ç½®åä¸­æ–­æ‰§è¡Œ
            
        Returns:
            AI çš„æœ€ç»ˆå›å¤æ–‡æœ¬
        """
        def _notify(msg_type: str, **kwargs):
            if progress_callback:
                try:
                    progress_callback({"type": msg_type, **kwargs})
                except Exception:
                    pass
        
        def _is_cancelled():
            return cancel_event is not None and cancel_event.is_set()

        # ğŸ”¥ æ€§èƒ½ç›‘æ§ï¼šè®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        tool_calls_list = []   # è®°å½•æœ¬æ¬¡è°ƒç”¨çš„æ‰€æœ‰å·¥å…·
        consecutive_errors = 0 # ä¿®å¤é£é™©3ï¼šè¿ç»­é”™è¯¯è®¡æ•°å™¨

        # ä¿®å¤é£é™©4ï¼šsystem_hints ç§»åˆ° user_message å‰é¢è€Œé system_prompt æœ«å°¾
        # åŸå› ï¼šDeepSeek å¯¹ system_prompt é¦–å°¾æ•æ„Ÿï¼Œè­¦å‘Šæ”¾æœ«å°¾ä¼šå†²æ·¡äººè®¾
        # ç°åœ¨è­¦å‘Šä»¥ [System Note] å½¢å¼è´´åœ¨ç”¨æˆ·æ¶ˆæ¯æœ€å‰é¢ï¼Œæƒé‡æ›´é«˜
        hints_prefix = ""
        if self.system_hints:
            hints_text = "\n".join(self.system_hints)
            hints_prefix = f"[System Note]\n{hints_text}\n[/System Note]\n\n"
            self.system_hints.clear()

        # ä¿®å¤é£é™©1ï¼šé…æ–¹å¬å›ä¸æ¶‰åŠå†™æ“ä½œï¼Œä¸éœ€è¦åŠ é”
        recipe_reminder = self.memory_system.recall_recipe(user_input, n_results=4)
        if recipe_reminder:
            user_input_with_context = (
                f"{hints_prefix}"
                f"ã€âš¡ æ‰§è¡Œå‰å¿…è¯»é…æ–¹ - å¼ºåˆ¶è§„èŒƒã€‘\n{recipe_reminder}\n\n"
                f"---\nç”¨æˆ·æŒ‡ä»¤ï¼š{user_input}"
            )
        else:
            user_input_with_context = f"{hints_prefix}{user_input}" if hints_prefix else user_input

        messages = [{"role": "system", "content": system_content}]
        messages.extend(self.chat_history)
        messages.append({"role": "user", "content": user_input_with_context})

        # ä¿®å¤é£é™©3ï¼šmax_iterations ä¿æŒ15ï¼Œä½†åŠ è¿ç»­é”™è¯¯æˆªæ–­
        max_iterations = 15
        iteration = 0
        ai_reply = ""
        
        while iteration < max_iterations:
            # ğŸ›‘ æ£€æŸ¥å–æ¶ˆæ ‡å¿—
            if _is_cancelled():
                logger.info("ğŸ›‘ ç”¨æˆ·å–æ¶ˆäº†å½“å‰æ“ä½œ")
                ai_reply = "å¥½çš„æŒ‡æŒ¥å®˜ï¼Œå·²åœæ­¢å½“å‰æ“ä½œã€‚æœ‰ä»€ä¹ˆéœ€è¦å¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘~ [OK]"
                break
            
            iteration += 1
            logger.info(f"ğŸ¤– AIæ€è€ƒè½®æ¬¡: {iteration}")
            _notify("thinking", iteration=iteration)
            
            # è°ƒç”¨ DeepSeekï¼ˆå¸¦é‡è¯• + é™çº§ï¼‰
            response = None
            for attempt in range(3):  # æœ€å¤šé‡è¯• 3 æ¬¡
                try:
                    response = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=messages,
                        tools=tools_schema,
                        tool_choice="auto",
                        stream=False,
                        temperature=0.8,
                        max_tokens=8192
                    )
                    break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                except (APITimeoutError, APIConnectionError) as e:
                    wait = 2 ** attempt  # 1s, 2s, 4s æŒ‡æ•°é€€é¿
                    logger.warning(f"âš ï¸ API ç½‘ç»œé”™è¯¯ (ç¬¬{attempt+1}æ¬¡): {e}ï¼Œ{wait}ç§’åé‡è¯•...")
                    time.sleep(wait)
                except RateLimitError as e:
                    wait = 5 * (attempt + 1)  # 5s, 10s, 15s
                    logger.warning(f"âš ï¸ API é™æµ (ç¬¬{attempt+1}æ¬¡): {e}ï¼Œ{wait}ç§’åé‡è¯•...")
                    time.sleep(wait)
                except APIStatusError as e:
                    logger.error(f"âŒ API çŠ¶æ€é”™è¯¯: {e.status_code} {e.message}")
                    break  # æœåŠ¡ç«¯é”™è¯¯ä¸é‡è¯•
                except Exception as e:
                    logger.error(f"âŒ API æœªçŸ¥é”™è¯¯: {e}")
                    break
            
            if response is None:
                ai_reply = "æŒ‡æŒ¥å®˜ï¼Œæˆ‘çš„ç½‘ç»œå¥½åƒä¸å¤ªç¨³å®šï¼Œè¿æ¥ä¸ä¸ŠæœåŠ¡å™¨â€¦ç­‰ä¸€ä¸‹å†è¯•è¯•ï¼Ÿ[Sorrow]"
                break
            
            message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if message.tool_calls:
                logger.info(f"ğŸ”§ AIè¯·æ±‚ä½¿ç”¨å·¥å…·: {len(message.tool_calls)} ä¸ª")
                _notify("tool_start", count=len(message.tool_calls))
                
                # æŠŠ AI çš„å·¥å…·è°ƒç”¨æ„å›¾åŠ å…¥å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
                for tool_call in message.tool_calls:
                    func_name = tool_call.function.name
                    
                    # [ä¿®å¤C-2] é˜²æ­¢ API è¿”å›ç•¸å½¢ JSON å¯¼è‡´å´©æºƒ
                    try:
                        func_args = json.loads(tool_call.function.arguments)
                    except (json.JSONDecodeError, TypeError) as e:
                        # å¤šå±‚ä¿®å¤ç­–ç•¥
                        func_args = None
                        raw = tool_call.function.arguments or ""
                        
                        # ç­–ç•¥1: ç»™è£¸å­—æ ‡è¯†ç¬¦åŠ å¼•å·
                        try:
                            import re
                            fixed = re.sub(
                                r':\s*([A-Za-z_][A-Za-z0-9_]*)\s*([,}\]])',
                                lambda m: ': "' + m.group(1) + '"' + m.group(2)
                                    if m.group(1) not in ('true', 'false', 'null')
                                    else m.group(0),
                                raw
                            )
                            func_args = json.loads(fixed)
                            logger.warning(f"âš ï¸ å·¥å…·å‚æ•° JSON å·²è‡ªåŠ¨ä¿®å¤ï¼ˆè£¸æ ‡è¯†ç¬¦ï¼‰: {func_name}")
                        except Exception:
                            pass
                        
                        # ç­–ç•¥1.5: å¯¹ create_file_directly ç›´æ¥æ­£åˆ™æå–ï¼ˆä¸ä¾èµ– JSON è§£æï¼‰
                        if func_args is None and func_name == "create_file_directly":
                            try:
                                import re as _re
                                fp_match = _re.search(r'"file_path"\s*:\s*"([^"]+)"', raw)
                                ct_match = _re.search(r'"content"\s*:\s*"', raw)
                                if fp_match and ct_match:
                                    file_path = fp_match.group(1)
                                    # content ä»åŒ¹é…ç»“æŸä½ç½®å–åˆ°å­—ç¬¦ä¸²æœ«å°¾
                                    content_start = ct_match.end()
                                    content_raw = raw[content_start:]
                                    # å»æ‰å°¾éƒ¨å¯èƒ½çš„ "} æˆ–æœªé—­åˆçš„éƒ¨åˆ†
                                    content_raw = content_raw.rstrip()
                                    if content_raw.endswith('"}'):
                                        content_raw = content_raw[:-2]
                                    elif content_raw.endswith('"'):
                                        content_raw = content_raw[:-1]
                                    # åè½¬ä¹‰ JSON å­—ç¬¦ä¸²ä¸­çš„è½¬ä¹‰å­—ç¬¦
                                    content_text = content_raw.replace('\\n', '\n').replace('\\t', '\t').replace('\\"', '"').replace('\\\\', '\\')
                                    func_args = {"file_path": file_path, "content": content_text}
                                    logger.warning(f"âš ï¸ å·¥å…·å‚æ•° JSON å·²è‡ªåŠ¨ä¿®å¤ï¼ˆæ­£åˆ™æå–ï¼‰: {func_name}")
                            except Exception:
                                pass
                        
                        # ç­–ç•¥2: æˆªæ–­ä¿®å¤ï¼ˆæ”¹è¿›ç‰ˆï¼šå­—ç¬¦ä¸²æ„ŸçŸ¥çš„æ‹¬å·è®¡æ•°ï¼‰
                        if func_args is None:
                            try:
                                repair = raw.rstrip()
                                # å­—ç¬¦ä¸²æ„ŸçŸ¥ï¼šéå†æ—¶è·Ÿè¸ªæ˜¯å¦åœ¨å¼•å·å†…
                                in_str = False
                                open_braces = 0
                                open_brackets = 0
                                for i, ch in enumerate(repair):
                                    if ch == '"' and (i == 0 or repair[i-1] != '\\'):
                                        in_str = not in_str
                                    elif not in_str:
                                        if ch == '{': open_braces += 1
                                        elif ch == '}': open_braces -= 1
                                        elif ch == '[': open_brackets += 1
                                        elif ch == ']': open_brackets -= 1
                                # è¡¥å…¨
                                if in_str:
                                    repair += '"'
                                repair += '}' * max(0, open_braces)
                                repair += ']' * max(0, open_brackets)
                                func_args = json.loads(repair)
                                logger.warning(f"âš ï¸ å·¥å…·å‚æ•° JSON å·²è‡ªåŠ¨ä¿®å¤ï¼ˆæˆªæ–­è¡¥å…¨ï¼‰: {func_name}")
                            except Exception:
                                pass
                        
                        # æ‰€æœ‰ç­–ç•¥å¤±è´¥
                        if func_args is None:
                            logger.error(f"å·¥å…·å‚æ•°è§£æå¤±è´¥: {func_name}, åŸå§‹å‚æ•°: {raw[:500]}..., é”™è¯¯: {e}")
                            # ç»™ AI æ¸…æ™°çš„é”™è¯¯å›é¦ˆï¼Œé¿å…é‡è¯•æ­»å¾ªç¯
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": (
                                    f"âŒ JSON å‚æ•°è§£æå¤±è´¥ï¼ˆå¯èƒ½æ˜¯å†…å®¹å¤ªé•¿è¢«æˆªæ–­ï¼‰ã€‚"
                                    f"è¯·ä¸è¦é‡è¯•ç›¸åŒå†…å®¹ï¼å»ºè®®å¯¹ç”¨æˆ·è¯´æ˜æƒ…å†µï¼Œæˆ–å°†å†…å®¹æ‹†åˆ†ä¸ºæ›´å°çš„éƒ¨åˆ†ã€‚"
                                )
                            })
                            consecutive_errors += 1
                            if consecutive_errors >= 2:
                                ai_reply = "æŒ‡æŒ¥å®˜ï¼Œæ–‡ä»¶å†…å®¹å¤ªé•¿å¯¼è‡´å·¥å…·è°ƒç”¨å¤±è´¥äº†ï¼Œæˆ‘é‡æ–°æ¢ä¸ªæ–¹å¼è¯•è¯•æˆ–è€…ä½ æ¥é…åˆä¸€ä¸‹ï¼Ÿ[Worry]"
                                break
                            continue
                    
                    # ä¿®å¤é£é™©3+æ—¥å¿—å¢å¼ºï¼šæ˜¾ç¤ºå·¥å…·å‚æ•°ï¼Œæ–¹ä¾¿è°ƒè¯•è·¯å¾„é—®é¢˜
                    logger.info(f"ğŸ“ è°ƒç”¨å·¥å…·: {func_name} | å‚æ•°: {json.dumps(func_args, ensure_ascii=False)[:200]}")
                    _notify("tool_call", tool=func_name)
                    
                    # ğŸ›‘ å·¥å…·æ‰§è¡Œå‰å†æ¬¡æ£€æŸ¥å–æ¶ˆ
                    if _is_cancelled():
                        logger.info("ğŸ›‘ ç”¨æˆ·åœ¨å·¥å…·è°ƒç”¨å‰å–æ¶ˆäº†æ“ä½œ")
                        ai_reply = "å¥½çš„æŒ‡æŒ¥å®˜ï¼Œå·²åœæ­¢å½“å‰æ“ä½œã€‚æœ‰ä»€ä¹ˆéœ€è¦å¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘~ [OK]"
                        break
                    
                    tool_calls_list.append(func_name)

                    # å·¥å…·æ‰§è¡Œï¼ˆå¸¦è¿ç»­é”™è¯¯æˆªæ–­ï¼‰
                    try:
                        result = tool_executor(func_name, func_args)
                        consecutive_errors = 0  # æˆåŠŸåˆ™é‡ç½®è®¡æ•°å™¨
                    except Exception as e:
                        consecutive_errors += 1
                        logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {func_name} â†’ {e} ï¼ˆè¿ç»­å¤±è´¥ {consecutive_errors} æ¬¡ï¼‰")
                        result = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}"
                        # ä¿®å¤é£é™©3ï¼šè¿ç»­ 3 æ¬¡å·¥å…·æŠ¥é”™ï¼Œæˆªæ–­å¹¶è¯·æ±‚äººå·¥ä»‹å…¥
                        if consecutive_errors >= 3:
                            logger.error("ğŸš¨ è¿ç»­ 3 æ¬¡å·¥å…·å¤±è´¥ï¼Œå¼ºåˆ¶æˆªæ–­ï¼Œè¯·äººå·¥ä»‹å…¥ï¼")
                            ai_reply = "æŒ‡æŒ¥å®˜ï¼Œæˆ‘è¿ç»­é‡åˆ°äº† 3 æ¬¡å·¥å…·æŠ¥é”™ï¼Œå¯èƒ½æ˜¯ç¯å¢ƒé—®é¢˜ï¼Œéœ€è¦ä½ æ¥çœ‹ä¸€ä¸‹ï½[Worry]"
                            break
                    
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
                
                # ä¿®å¤é£é™©3ï¼šè¿ç»­é”™è¯¯æˆªæ–­åé€€å‡ºä¸»å¾ªç¯
                if consecutive_errors >= 3:
                    break
                # ğŸ›‘ å–æ¶ˆåé€€å‡ºä¸»å¾ªç¯
                if _is_cancelled():
                    break

                # ç»§ç»­ä¸‹ä¸€è½®ï¼Œè®© AI æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆå›å¤
                continue
            
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è·å–å›å¤
                ai_reply = message.content
                break
        
        else:
            # è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
            ai_reply = "æŒ‡æŒ¥å®˜ï¼Œè¿™ä¸ªé—®é¢˜æœ‰ç‚¹å¤æ‚ï¼Œæˆ‘éœ€è¦æ›´å¤šæ—¶é—´æ€è€ƒ..."
        
        # ğŸ”¥ æ€§èƒ½ç›‘æ§ï¼šè®°å½•ç»“æŸæ—¶é—´å’Œç»Ÿè®¡æ•°æ®
        elapsed_time = time.time() - start_time
        tool_count = len(tool_calls_list)
        
        # è®°å½•åˆ°æ€§èƒ½æ—¥å¿—ï¼ˆä¿ç•™æœ€è¿‘20æ¡ï¼‰
        self.performance_log.append({
            "task": user_input[:50],  # æˆªå–å‰50å­—ç¬¦
            "time": round(elapsed_time, 2),
            "steps": tool_count,
            "tools_used": tool_calls_list,
            "timestamp": datetime.datetime.now().strftime("%H:%M:%S")
        })
        if len(self.performance_log) > 20:
            self.performance_log.pop(0)  # ç§»é™¤æœ€æ—§çš„è®°å½•
        
        logger.info(f"â±ï¸ [æ€§èƒ½] æœ¬æ¬¡ä»»åŠ¡è€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œè°ƒç”¨å·¥å…·: {tool_count}ä¸ª")
        
        # ğŸ”¥ æ€§èƒ½è­¦å‘Šï¼šå¦‚æœå¤ªæ…¢æˆ–è°ƒç”¨å¤ªå¤šå·¥å…·ï¼Œç»™AIå‘é€ä¼˜åŒ–å»ºè®®
        # [ä¼˜åŒ–] é™ä½è§¦å‘é˜ˆå€¼ï¼š5ç§’ + 2ä¸ªå·¥å…·ï¼Œæ›´å®¹æ˜“è§¦å‘å­¦ä¹ 
        if elapsed_time > 5 and tool_count > 2:
            warning = f"""âš ï¸ æ€§èƒ½è­¦å‘Šï¼šä¸Šä¸€ä¸ªä»»åŠ¡è€—æ—¶ {elapsed_time:.1f}ç§’ï¼Œè°ƒç”¨äº† {tool_count} ä¸ªå·¥å…·ã€‚

è¯·åæ€ï¼š
- æ˜¯å¦æœ‰æ›´å¿«çš„æ–¹æ³•ï¼Ÿï¼ˆå¦‚ç”¨ create_file_directly ä»£æ›¿æ‰“å¼€è®°äº‹æœ¬ï¼‰
- æ˜¯å¦å¯ä»¥ç”¨å¿«æ·é”®ä»£æ›¿ç‚¹å‡»èœå•ï¼Ÿï¼ˆå¦‚ Ctrl+S ä¿å­˜ï¼‰
- æ˜¯å¦å¯ä»¥åˆå¹¶å¤šä¸ªæ“ä½œä¸ºä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼Ÿ

è®°ä½ï¼šç”¨æˆ·è¦çš„æ˜¯ç»“æœï¼Œä¸æ˜¯è¿‡ç¨‹ã€‚ä¼˜å…ˆä½¿ç”¨ã€å·¥å…·ä¼˜å…ˆçº§1-2ã€‘çš„æ–¹æ³•ã€‚

æœ€è¿‘è°ƒç”¨çš„å·¥å…·ï¼š{', '.join(tool_calls_list[-5:])}"""
            self.system_hints.append(warning)  # ä¸‹æ¬¡å¯¹è¯æ—¶è‡ªåŠ¨æ³¨å…¥
            logger.warning(f"ğŸ¢ æ€§èƒ½è­¦å‘Šå·²ç”Ÿæˆï¼Œå°†åœ¨ä¸‹æ¬¡å¯¹è¯æ—¶æé†’AIä¼˜åŒ–")
            
            # ğŸ”¥ è‡ªåŠ¨å­¦ä¹ ï¼šæŠŠæ€§èƒ½æ•™è®­ä¿å­˜åˆ°é•¿æœŸè®°å¿†ï¼ˆæ°¸ä¹…è®°ä½ï¼‰
            self.learn_from_performance(user_input, tool_calls_list, elapsed_time)
        
        # æ›´æ–°å¯¹è¯å†å²
        self.chat_history.append({"role": "user", "content": user_input})
        self.chat_history.append({"role": "assistant", "content": ai_reply})
        self.trim_history()
        
        # ä¿å­˜äº¤äº’æ—¶é—´
        current_mem = self.load_memory()
        current_mem["last_interaction"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.save_memory(current_mem)
        
        # æ½œæ„è¯†è®°å¿†ï¼šåå°åˆ†æå¯¹è¯
        self.analyze_and_store_memory(user_input, ai_reply)
        
        return ai_reply

    # ========================
    # ğŸ§  æ½œæ„è¯†è®°å¿†ç³»ç»Ÿ (Subconscious Memory)
    # ========================
    def analyze_and_store_memory(self, user_text: str, ai_reply: str):
        """
        è®© AI åæ€åˆšæ‰çš„å¯¹è¯ï¼Œæå–æœ‰ä»·å€¼çš„è®°å¿†ã€‚
        åœ¨åå°çº¿ç¨‹è¿è¡Œï¼Œä¸å¡ä½å¯¹è¯ã€‚
        """
        def _background_task():
            # 1. æ„é€ ä¸“é—¨ç”¨æ¥æå–è®°å¿†çš„ Prompt
            reflection_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œæå–å…³äºç”¨æˆ·çš„ã€é•¿æœŸäº‹å®ã€‘æˆ–ã€é‡è¦åå¥½ã€‘ã€‚

ç”¨æˆ·è¯´ï¼š{user_text}
AIå›å¤ï¼š{ai_reply}

ã€æå–è§„åˆ™ã€‘
- åªæå–å¯ä»¥é•¿æœŸè®°ä½çš„äº‹å®ï¼ˆå¦‚ï¼šç”¨æˆ·çš„è®¡åˆ’ã€åå¥½ã€åŒæ¶ã€ä¹ æƒ¯ã€äººé™…å…³ç³»ç­‰ï¼‰
- ä¸è¦æå–ä¸´æ—¶æ€§ä¿¡æ¯ï¼ˆå¦‚ï¼šä»Šå¤©å¤©æ°”ã€æ­£åœ¨åšçš„äº‹ï¼‰
- å¦‚æœæ²¡æœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¾“å‡º None

ã€è¾“å‡ºè¦æ±‚ã€‘
å¦‚æœæœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦Markdownï¼Œä¸è¦åºŸè¯ï¼‰ï¼š
{{"content": "é™ˆè¿°å¥æ ¼å¼çš„äº‹å®", "importance": 1åˆ°5çš„æ•´æ•°}}

importance ç­‰çº§è¯´æ˜ï¼š
- 5: æ ¸å¿ƒèº«ä»½/æ°¸ä¹…åå¥½ï¼ˆå¦‚ï¼šåå­—ã€MBTIã€ç»å¯¹ç¦å¿Œï¼‰
- 4: é‡è¦è®¡åˆ’/å…³ç³»ï¼ˆå¦‚ï¼šè€ƒé©¾ç…§ã€å¥³æœ‹å‹å«ä»€ä¹ˆï¼‰
- 3: ä¸€èˆ¬åå¥½ï¼ˆå¦‚ï¼šå–œæ¬¢åƒç”œé£Ÿï¼‰
- 2: ä¸´æ—¶çŠ¶æ€ï¼ˆå¦‚ï¼šæœ€è¿‘åœ¨å­¦Pythonï¼‰
- 1: çç¢ä¿¡æ¯

ç¤ºä¾‹è¾“å‡ºï¼š
{{"content": "æŒ‡æŒ¥å®˜æ‰“ç®—ä¸‹ä¸ªæœˆè€ƒé©¾ç…§", "importance": 4}}
"""
            
            try:
                # 2. è°ƒç”¨ LLMï¼ˆéæµå¼ï¼Œè§£æ JSONï¼‰
                response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": reflection_prompt}],
                    max_tokens=150,
                    temperature=0.3  # ä½æ¸©åº¦ï¼Œæ›´ç¨³å®š
                )
                result = response.choices[0].message.content.strip()
                
                # 3. æ£€æŸ¥æ˜¯å¦æœ‰å€¼å¾—è®°å¿†çš„å†…å®¹
                if "None" in result or "none" in result or "{" not in result:
                    return  # æ²¡ä»€ä¹ˆå¥½è®°çš„
                
                # 4. è§£æ JSON
                # æ¸…æ´—å¯èƒ½çš„ Markdown åŒ…è£¹
                clean_json = result.replace("```json", "").replace("```", "").strip()
                memory_item = json.loads(clean_json)
                
                content = memory_item.get("content", "")
                importance = memory_item.get("importance", 3)
                
                if not content:
                    return
                
                # 5. å»é‡æ£€æŸ¥ï¼šå¦‚æœå·²æœ‰é«˜åº¦ç›¸ä¼¼çš„è®°å¿†ï¼Œè·³è¿‡å­˜å‚¨
                try:
                    existing = self.memory_system.search_memory(content, n_results=1, threshold=0.5)
                    if existing:
                        logger.debug(f"ğŸ§  [æ½œæ„è¯†] è®°å¿†å·²å­˜åœ¨ï¼Œè·³è¿‡: '{content[:30]}' (ç›¸ä¼¼: {existing[0].get('content', '')[:30]})")
                        return
                except Exception:
                    pass  # å»é‡å¤±è´¥ä¸å½±å“å­˜å‚¨
                
                # 6. å­˜å…¥é•¿æœŸè®°å¿†ï¼ˆåŠ é”é˜²æ­¢å¤šçº¿ç¨‹å†™å…¥å†²çªï¼‰
                with self._memory_lock:
                    self.memory_system.add_memory(content, category="fact", metadata={"importance": importance})
                logger.info(f"ğŸ§  [æ½œæ„è¯†] å·²è‡ªåŠ¨å½’æ¡£è®°å¿†ï¼š{content} (é‡è¦åº¦: {importance})")
                
            except json.JSONDecodeError as e:
                logger.debug(f"æ½œæ„è¯†è®°å¿†è§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"æ½œæ„è¯†è®°å¿†æå–å¤±è´¥: {e}")
        
        # å¯åŠ¨åå°çº¿ç¨‹ï¼Œä¸é˜»å¡ä¸»å¯¹è¯
        thread = threading.Thread(target=_background_task, daemon=True)
        thread.start()

    # ä»»åŠ¡æ­¥æ•°åŸºå‡†èŒƒå›´ (min_steps, max_steps)
    # ä¿®å¤é£é™©2ï¼šæ”¹ä¸ºèŒƒå›´è€Œéå›ºå®šå€¼ï¼Œé¿å…å¤æ‚ä»»åŠ¡è¢«è¯¯åˆ¤ä¸ºå†—ä½™
    # è¶…è¿‡ max_steps æ‰è§¦å‘åæ€
    TASK_BASELINES = {
        "obsidian": (1, 2),   # å†™ç¬”è®°ï¼š1æ­¥æœ€ä¼˜ï¼Œ2æ­¥å¯æ¥å—
        "é»‘æ›œçŸ³":   (1, 2),
        "é»‘è¯çŸ³":   (1, 2),
        "é»‘é’¥åŒ™":   (1, 2),
        "githubæœç´¢": (1, 2), # å•çº¯æœç´¢ï¼š1-2æ­¥
        "github":   (1, 4),   # å¤æ‚GitHubæ“ä½œï¼ˆæœç´¢+è¯»+åˆ›å»ºIssueï¼‰ï¼šæœ€å¤š4æ­¥
        "åˆ›å»ºæ–‡ä»¶": (1, 1),
        "å†™æ–‡ä»¶":   (1, 1),
        "ä¿å­˜æ–‡ä»¶": (1, 1),
    }

    def _get_task_baseline(self, user_task: str) -> tuple:
        """
        æ ¹æ®ä»»åŠ¡æè¿°è·å–æ­¥æ•°åŸºå‡†èŒƒå›´ (min, max)
        è¶…è¿‡ max æ‰è§¦å‘åæ€ï¼Œé¿å…å¤æ‚ä»»åŠ¡è¢«è¯¯åˆ¤
        """
        task_lower = user_task.lower()
        # ä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„å…³é”®è¯ï¼ˆgithubæœç´¢ > githubï¼‰
        sorted_keys = sorted(self.TASK_BASELINES.keys(), key=len, reverse=True)
        for keyword in sorted_keys:
            if keyword in task_lower:
                return self.TASK_BASELINES[keyword]
        return (1, 4)  # æœªçŸ¥ä»»åŠ¡é»˜è®¤ 1-4 æ­¥éƒ½å¯æ¥å—

    def learn_from_performance(self, user_task: str, tools_used: list, elapsed_time: float):
        """
        ğŸ”¥ ä»æ“ä½œä¸­è‡ªåŠ¨å­¦ä¹ ï¼Œå­˜å…¥é…æ–¹å‰å…ˆéªŒè¯æ˜¯å¦èµ°äº†å¼¯è·¯
        v2.1 æ–°å¢ï¼š
        - éªŒè¯ç¯èŠ‚ï¼šå­˜é…æ–¹å‰å…ˆé—® AI æœ‰æ²¡æœ‰å¤šä½™æ­¥éª¤
        - åŸºå‡†æ£€æŸ¥ï¼šè¶…è¿‡å†å²æœ€ä¼˜æ­¥æ•° 1.5 å€ä¹Ÿè§¦å‘åæ€
        - é˜²æ­¢å­¦é”™ï¼šæˆåŠŸä½†ä½æ•ˆçš„æ–¹æ³•ä¸ä¼šè¢«å­˜ä¸ºæ­£ç¡®é…æ–¹
        """
        def _background_task():
            try:
                tool_count = len(tools_used)
                tools_str = ' -> '.join(tools_used)

                # Step 1: éªŒè¯ç¯èŠ‚ - å­˜é…æ–¹å‰å…ˆé—® AI æœ‰æ²¡æœ‰èµ°å¼¯è·¯
                verify_prompt = f"""ä½ åˆšæ‰å®Œæˆäº†ä¸€ä¸ªä»»åŠ¡ï¼Œè¯·åšã€æ‰§è¡Œè´¨é‡å®¡æŸ¥ã€‘ã€‚

ã€ä»»åŠ¡ã€‘ï¼š{user_task}
ã€è€—æ—¶ã€‘ï¼š{elapsed_time:.1f}ç§’
ã€å·¥å…·è°ƒç”¨é¡ºåºã€‘ï¼š{tools_str}
ã€æ€»æ­¥æ•°ã€‘ï¼š{tool_count}æ­¥

è¯·åˆ¤æ–­è¿™æ¬¡æ‰§è¡Œæ˜¯å¦èµ°äº†å¼¯è·¯ï¼š

ã€å®¡æŸ¥é‡ç‚¹ã€‘
1. æœ‰æ²¡æœ‰æœ¬å¯ä»¥ä¸ç”¨ä½†ç”¨äº†çš„å·¥å…·ï¼Ÿ
   ä¾‹å¦‚ï¼šå·²çŸ¥è·¯å¾„è¿˜å»è°ƒç”¨ list_directory æˆ– list_allowed_directories
   ä¾‹å¦‚ï¼šåŒä¸€å·¥å…·è¿ç»­è°ƒç”¨å¤šæ¬¡ï¼ˆwrite_file è°ƒç”¨ 3 æ¬¡ï¼‰
   ä¾‹å¦‚ï¼šç¬¬ä¸€æ¬¡ç”¨é”™è·¯å¾„å¤±è´¥ï¼Œç¬¬äºŒæ¬¡æ‰ç”¨å¯¹ï¼ˆè¯´æ˜é…æ–¹è·¯å¾„æœ‰è¯¯ï¼‰
2. æœ€ä¼˜æ–¹æ¡ˆåº”è¯¥å‡ æ­¥ï¼Ÿï¼ˆObsidianå†™ç¬”è®°=1æ­¥ï¼ŒGitHubæœç´¢=1æ­¥ï¼‰

ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åºŸè¯ï¼š
{{"has_redundancy": trueæˆ–false, "redundant_steps": ["å¤šä½™æ­¥éª¤1"], "optimal_steps": æœ€ä¼˜æ­¥æ•°, "root_cause": "æ ¹æœ¬åŸå› ä¸€å¥è¯", "correct_solution": "æ­£ç¡®åšæ³•ä¸€å¥è¯å«å…·ä½“å·¥å…·åå’Œè·¯å¾„"}}

å¦‚æœæ‰§è¡Œå®Œå…¨æœ€ä¼˜ï¼Œè¾“å‡ºï¼š{{"has_redundancy": false}}"""

                verify_resp = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": verify_prompt}],
                    max_tokens=300,
                    temperature=0.1
                )
                verify_result = verify_resp.choices[0].message.content.strip()
                clean_verify = verify_result.replace("```json", "").replace("```", "").strip()
                verify_data = json.loads(clean_verify)

                has_redundancy = verify_data.get("has_redundancy", False)
                redundant_steps = verify_data.get("redundant_steps", [])
                optimal_steps = verify_data.get("optimal_steps", tool_count)
                root_cause = verify_data.get("root_cause", "")
                correct_solution = verify_data.get("correct_solution", "")

                if has_redundancy:
                    logger.warning(f"âš ï¸ [è´¨é‡å®¡æŸ¥] å‘ç°å†—ä½™ï¼å®é™…{tool_count}æ­¥ vs æœ€ä¼˜{optimal_steps}æ­¥ | {root_cause}")
                else:
                    logger.info(f"âœ… [è´¨é‡å®¡æŸ¥] æ‰§è¡Œåˆæ ¼ï¼ˆ{tool_count}æ­¥ï¼‰")

                # Step 2: åŸºå‡†æ£€æŸ¥ - è¶…è¿‡ max_steps æ‰è§¦å‘åæ€
                # ä¿®å¤é£é™©2ï¼šä½¿ç”¨èŒƒå›´(min,max)è€Œéå›ºå®šå€¼ï¼Œé¿å…å¤æ‚ä»»åŠ¡è¢«è¯¯åˆ¤
                baseline_min, baseline_max = self._get_task_baseline(user_task)
                if tool_count > baseline_max and not has_redundancy:
                    has_redundancy = True
                    root_cause = root_cause or f"æ­¥æ•°({tool_count})è¶…è¿‡å¯æ¥å—ä¸Šé™({baseline_max}æ­¥)"
                    logger.warning(f"âš ï¸ [åŸºå‡†æ£€æŸ¥] æ­¥æ•°è¶…æ ‡ï¼š{tool_count}æ­¥ > ä¸Šé™{baseline_max}æ­¥")
                elif tool_count <= baseline_max:
                    logger.info(f"âœ… [åŸºå‡†æ£€æŸ¥] æ­¥æ•°åˆæ ¼ï¼ˆ{tool_count}æ­¥ï¼Œä¸Šé™{baseline_max}æ­¥ï¼‰")

                # Step 3: æ ¹æ®éªŒè¯ç»“æœç”Ÿæˆé…æ–¹å†…å®¹
                if has_redundancy and correct_solution:
                    # æœ‰å†—ä½™ï¼šå­˜æ­£ç¡®åšæ³• + ç¦æ­¢é¡¹
                    lesson = f"{correct_solution} ã€ç¦æ­¢ã€‘{', '.join(redundant_steps[:2])} ã€åŸå› ã€‘{root_cause}"
                    logger.info(f"ğŸ“š [å­¦ä¹ ] å‘ç°å¼¯è·¯ï¼Œå­˜å…¥çº æ­£é…æ–¹ï¼š{lesson[:80]}")
                else:
                    # æ— å†—ä½™ï¼šç”Ÿæˆå¸¸è§„æœ€ä½³å®è·µ
                    learning_prompt = f"""åˆ†æä»¥ä¸‹æ“ä½œï¼Œæå–æœ€ä½³å®è·µã€‚

ã€ä»»åŠ¡ã€‘ï¼š{user_task}
ã€è€—æ—¶ã€‘ï¼š{elapsed_time:.1f}ç§’
ã€å·¥å…·é“¾ã€‘ï¼š{tools_str}

æç‚¼ä¸‹æ¬¡åŒç±»ä»»åŠ¡çš„æœ€ä¼˜åšæ³•ï¼Œä¸€å¥è¯ã€‚
æ ¼å¼ï¼š{{"lesson": "å½“ç”¨æˆ·è¯´...æ—¶ï¼Œç›´æ¥ç”¨...ï¼Œæ³¨æ„..."}}
å¦‚æœå·²æ˜¯æœ€ä¼˜ï¼Œè¾“å‡º None"""

                    learn_resp = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[{"role": "user", "content": learning_prompt}],
                        max_tokens=150,
                        temperature=0.2
                    )
                    learn_result = learn_resp.choices[0].message.content.strip()

                    if "None" in learn_result or "{" not in learn_result:
                        logger.info("âœ… [å­¦ä¹ ] æœ¬æ¬¡æ‰§è¡Œå·²æ˜¯æœ€ä¼˜ï¼Œæ— éœ€å­˜é…æ–¹")
                        return

                    clean_learn = learn_result.replace("```json", "").replace("```", "").strip()
                    lesson_item = json.loads(clean_learn)
                    lesson = lesson_item.get("lesson", "")
                    if not lesson:
                        return

                # Step 4: æå–è¯­ä¹‰åŒ– triggerï¼Œé¿å…è¯­éŸ³è¯†åˆ«é”™è¯¯
                trigger_prompt = f"""ä»ä»¥ä¸‹å†…å®¹æå–è§¦å‘åœºæ™¯å…³é”®è¯ï¼ˆ3-5ä¸ªä¸­æ–‡è¯ï¼Œé€—å·åˆ†éš”ï¼‰ï¼š
ä»»åŠ¡ï¼š{user_task}
æ•™è®­ï¼š{lesson}
ç›´æ¥è¾“å‡ºå…³é”®è¯ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼š"""

                trigger_resp = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": trigger_prompt}],
                    max_tokens=30,
                    temperature=0.1
                )
                semantic_trigger = trigger_resp.choices[0].message.content.strip()

                # å­˜å…¥é…æ–¹ï¼ˆåŠ é”é˜²æ­¢ä¸æ½œæ„è¯†çº¿ç¨‹å†²çªï¼‰
                with self._memory_lock:
                    self.memory_system.add_recipe(
                        trigger=semantic_trigger,
                        solution=lesson,
                        metadata={
                            "source": "auto_learn",
                            "elapsed": elapsed_time,
                            "tools": ",".join(tools_used),
                            "optimal_steps": optimal_steps,
                            "actual_steps": tool_count,
                            "had_redundancy": has_redundancy,
                            "original_task": user_task[:100]
                        }
                    )
                logger.info(f"ğŸ“š [æ€§èƒ½å­¦ä¹ ] å·²å­˜å…¥é…æ–¹ï¼š{lesson[:80]}")

            except json.JSONDecodeError as e:
                logger.debug(f"æ€§èƒ½æ•™è®­è§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"æ€§èƒ½å­¦ä¹ å¤±è´¥: {e}")

        thread = threading.Thread(target=_background_task, daemon=True)
        thread.start()