"""
BrowserSkills â€” ğŸŒ æµè§ˆå™¨ç±»æŠ€èƒ½
ç½‘é¡µæœç´¢ã€é˜…è¯»ã€æ·±åº¦æµè§ˆï¼ˆPlaywrightï¼‰ã€è§†é¢‘æ’­æ”¾
"""
import logging, webbrowser, time
import requests

from .base import PLAYWRIGHT_AVAILABLE

logger = logging.getLogger("fuguang.skills")

_BROWSER_TOOLS_SCHEMA = [
    {"type":"function","function":{"name":"search_web","description":"è”ç½‘æœç´¢å®æ—¶ä¿¡æ¯ã€‚é€‚åˆåœºæ™¯: æ–°é—»/å¤©æ°”/æ¸¸æˆæ”»ç•¥/æœ€æ–°æ•°æ®ç­‰ã€‚âš ï¸ å¯¹äºå¸¸è¯†æ€§çŸ¥è¯†ï¼Œè¯·ç›´æ¥ç”¨ä½ è‡ªå·±çš„çŸ¥è¯†å›ç­”ï¼Œä¸è¦è°ƒç”¨æ­¤å·¥å…·ã€‚","parameters":{"type":"object","properties":{"query":{"type":"string","description":"æœç´¢å…³é”®è¯"}},"required":["query"]}}},
    {"type":"function","function":{"name":"open_website","description":"æ‰“å¼€å¸¸ç”¨ç½‘ç«™é¦–é¡µã€‚æ”¯æŒ: æ·˜å®/äº¬ä¸œ/Bç«™/çŸ¥ä¹/å¾®åš/GitHubç­‰","parameters":{"type":"object","properties":{"site_name":{"type":"string","description":"ç½‘ç«™åç§°"}},"required":["site_name"]}}},
    {"type":"function","function":{"name":"open_video","description":"ã€è‡ªåŠ¨æœç´¢å¹¶æ’­æ”¾è§†é¢‘ã€‘åœ¨Bç«™æœç´¢è§†é¢‘å¹¶è‡ªåŠ¨ç‚¹å‡»æ’­æ”¾ç¬¬ä¸€ä¸ªç»“æœã€‚æ”¯æŒsilent=trueå¿«é€Ÿæ¨¡å¼ã€‚","parameters":{"type":"object","properties":{"keyword":{"type":"string","description":"æœç´¢å…³é”®è¯"},"silent":{"type":"boolean","description":"é™é»˜æ¨¡å¼ï¼ˆé»˜è®¤falseï¼‰","default":False}},"required":["keyword"]}}},
    {"type":"function","function":{"name":"read_web_page","description":"ã€ç½‘é¡µé˜…è¯»å™¨ã€‘è¯»å–å¹¶æå–æŒ‡å®šç½‘é¡µçš„æ–‡å­—å†…å®¹ã€‚","parameters":{"type":"object","properties":{"url":{"type":"string","description":"è¦è¯»å–çš„ç½‘é¡µ URL"}},"required":["url"]}}},
    {"type":"function","function":{"name":"browse_website","description":"ã€æ·±åº¦æµè§ˆã€‘ä½¿ç”¨å…¨åŠŸèƒ½æµè§ˆå™¨è®¿é—®ç½‘é¡µï¼Œæ”¯æŒ JavaScript åŠ¨æ€åŠ è½½ã€‚æ¯” read_web_page æ›´å¼ºå¤§ã€‚","parameters":{"type":"object","properties":{"url":{"type":"string","description":"ç›®æ ‡ç½‘é¡µ URL"},"take_screenshot":{"type":"boolean","description":"æ˜¯å¦ä¿å­˜ç½‘é¡µæˆªå›¾"}},"required":["url"]}}},
]


class BrowserSkills:
    """æµè§ˆå™¨ç±»æŠ€èƒ½ Mixin"""
    _BROWSER_TOOLS = _BROWSER_TOOLS_SCHEMA

    # ========================
    # ğŸŒ è”ç½‘æœç´¢
    # ========================
    def search_web(self, query: str) -> str:
        logger.info(f"ğŸŒ æ­£åœ¨æœç´¢: {query}...")
        self.mouth.speak(f"æ­£åœ¨å¸®æŒ‡æŒ¥å®˜æŸ¥æ‰¾ {query}...")
        try:
            url = "https://google.serper.dev/search"
            payload = {"q": query, "gl": "cn", "hl": "zh-cn", "num": 5}
            headers = {"X-API-KEY": self.config.SERPER_API_KEY, "Content-Type": "application/json"}
            response = requests.post(url, json=payload, headers=headers, timeout=10)
            if response.status_code != 200:
                return f"æœç´¢å¤±è´¥,çŠ¶æ€ç  {response.status_code}"
            data = response.json()
            if "knowledgeGraph" in data:
                kg = data["knowledgeGraph"]
                return f"ã€å¿«é€Ÿç­”æ¡ˆã€‘\n{kg.get('title', '')}\n{kg.get('description', '')}\n"
            if "organic" not in data or not data["organic"]:
                return "æœªæ‰¾åˆ°æœ‰æ•ˆæœç´¢ç»“æœ"
            results = data["organic"][:5]
            summary = f"âœ… æœç´¢'{query}'æ‰¾åˆ° {len(results)} æ¡ç»“æœ:\n\n"
            for i, res in enumerate(results, 1):
                summary += f"ã€{i}ã€‘{res.get('title', 'æ— æ ‡é¢˜')}\n{res.get('snippet', 'æ— æ‘˜è¦')[:200]}...\n\n"
            return summary.strip()
        except Exception as e:
            logger.error(f"æœç´¢å¼‚å¸¸: {e}")
            return f"æœç´¢å¤±è´¥: {str(e)}"

    # ========================
    # ğŸ“– ç½‘é¡µæ·±åº¦é˜…è¯»
    # ========================
    def read_web_page(self, url: str) -> str:
        from bs4 import BeautifulSoup
        logger.info(f"ğŸ“– æ­£åœ¨é˜…è¯»ç½‘é¡µ: {url}")
        self.mouth.speak("æ­£åœ¨é˜…è¯»ç½‘é¡µå†…å®¹...")
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
            }
            response = requests.get(url, headers=headers, timeout=15)
            response.encoding = response.apparent_encoding or 'utf-8'
            if response.status_code != 200:
                return f"âŒ ç½‘é¡µè®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
            soup = BeautifulSoup(response.text, 'lxml')
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe', 'noscript']):
                tag.decompose()
            main_content = soup.find('main') or soup.find('article') or soup.find('div', class_='content') or soup.body
            text = main_content.get_text(separator='\n', strip=True) if main_content else soup.get_text(separator='\n', strip=True)
            lines = [line.strip() for line in text.splitlines() if line.strip()]
            clean_text = '\n'.join(lines)
            max_chars = 3000
            if len(clean_text) > max_chars:
                clean_text = clean_text[:max_chars] + f"\n\n... (å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ {max_chars} å­—ç¬¦)"
            title = soup.title.string if soup.title else "æ— æ ‡é¢˜"
            return f"ğŸ“„ ç½‘é¡µæ ‡é¢˜: {title}\n\n{clean_text}"
        except requests.Timeout:
            return "âŒ ç½‘é¡µè®¿é—®è¶…æ—¶ï¼ˆ15ç§’ï¼‰ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        except Exception as e:
            return f"âŒ ç½‘é¡µè¯»å–å¤±è´¥: {str(e)}"

    # ========================
    # ğŸŒ ç½‘ç«™æ‰“å¼€
    # ========================
    def open_website(self, site_name: str) -> str:
        logger.info(f"ğŸŒ æ­£åœ¨æ‰“å¼€: {site_name}")
        self.mouth.speak(f"æ­£åœ¨ä¸ºä½ æ‰“å¼€ {site_name}...")
        try:
            url = self.WEBSITE_REGISTRY.get(site_name)
            if url:
                webbrowser.open(url, new=2)
                return f"âœ… å·²æ‰“å¼€: {site_name}"
            return f"âŒ æœªçŸ¥ç½‘ç«™: {site_name}"
        except Exception as e:
            return f"âŒ æ‰“å¼€å¤±è´¥: {str(e)}"

    # ========================
    # ğŸŒ æµè§ˆå™¨ç®¡ç†ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
    # ========================
    def _get_browser_page(self):
        if not PLAYWRIGHT_AVAILABLE:
            return None
        try:
            if self._browser and self._browser.is_connected():
                if not self._browser_page or self._browser_page.is_closed():
                    self._browser_page = self._browser.new_page()
                return self._browser_page
            logger.info("ğŸš€ å¯åŠ¨æµè§ˆå™¨ï¼ˆé¦–æ¬¡æˆ–é‡è¿ï¼‰...")
            from playwright.sync_api import sync_playwright
            if not self._playwright:
                self._playwright = sync_playwright().start()
            self._browser = self._playwright.chromium.launch(headless=False)
            context = self._browser.new_context(
                user_agent=self.ghost.user_agent if self.ghost else "Mozilla/5.0",
                viewport={"width": 1920, "height": 1080}, locale="zh-CN")
            self._browser_page = context.new_page()
            return self._browser_page
        except Exception as e:
            logger.error(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}"); return None

    def _close_browser(self):
        try:
            if self._browser: self._browser.close()
            if self._playwright: self._playwright.stop()
            self._browser = None; self._browser_page = None; self._playwright = None
        except Exception as e:
            logger.warning(f"æµè§ˆå™¨å…³é—­å¼‚å¸¸: {e}")

    # ========================
    # ğŸ“º è§†é¢‘æœç´¢
    # ========================
    def open_video(self, keyword: str, silent: bool = False) -> str:
        """åœ¨Bç«™æœç´¢è§†é¢‘å¹¶è‡ªåŠ¨æ’­æ”¾ç¬¬ä¸€ä¸ªç»“æœ"""
        logger.info(f"ğŸ“º æ­£åœ¨æœç´¢è§†é¢‘: {keyword}")
        if not silent:
            self.mouth.speak(f"æ­£åœ¨å¸®ä½ æœç´¢å¹¶æ’­æ”¾ {keyword}...")
        try:
            import urllib.parse
            encoded_keyword = urllib.parse.quote(keyword)
            
            # [ä¿®å¤#12] å…ˆé€šè¿‡ Bç«™æœç´¢ API è·å–ç¬¬ä¸€ä¸ªè§†é¢‘çš„ bvid
            try:
                search_url = f"https://api.bilibili.com/x/web-interface/search/type?search_type=video&keyword={encoded_keyword}&page=1&page_size=1"
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Referer': 'https://www.bilibili.com'
                }
                resp = requests.get(search_url, headers=headers, timeout=8)
                if resp.status_code == 200:
                    data = resp.json()
                    results = data.get("data", {}).get("result", [])
                    if results:
                        first = results[0]
                        bvid = first.get("bvid", "")
                        title = first.get("title", "").replace("<em class=\"keyword\">", "").replace("</em>", "")
                        if bvid:
                            video_url = f"https://www.bilibili.com/video/{bvid}"
                            webbrowser.open(video_url, new=2)
                            if not silent:
                                self.mouth.speak(f"å·²æ‰“å¼€è§†é¢‘: {title[:30]}")
                            return f"âœ… æ­£åœ¨æ’­æ”¾: {title} ({video_url})"
            except Exception as e:
                logger.warning(f"âš ï¸ Bç«™ API æœç´¢å¤±è´¥ï¼Œå›é€€åˆ°æœç´¢é¡µ: {e}")
            
            # å›é€€ï¼šç›´æ¥æ‰“å¼€æœç´¢é¡µé¢
            url = f"https://search.bilibili.com/all?keyword={encoded_keyword}"
            webbrowser.open(url, new=2)
            if not silent:
                self.mouth.speak("å·²æ‰“å¼€Bç«™æœç´¢é¡µé¢ï¼Œè¯·é€‰æ‹©ä½ æƒ³çœ‹çš„è§†é¢‘~")
            return f"âœ… å·²åœ¨é»˜è®¤æµè§ˆå™¨ä¸­æ‰“å¼€Bç«™æœç´¢: {keyword}"
        except Exception as e:
            return f"âŒ è§†é¢‘æ’­æ”¾å¤±è´¥: {str(e)}"

    # ========================
    # ğŸŒ èµ›åšå¹½çµï¼šæ·±åº¦æµè§ˆ
    # ========================
    def browse_website(self, url: str, take_screenshot: bool = False) -> str:
        if not self.ghost:
            return self.read_web_page(url)
        logger.info(f"ğŸŒ [æ·±åº¦æµè§ˆ] AI è¯·æ±‚è®¿é—®: {url}")
        self.mouth.speak("æ­£åœ¨æ·±åº¦è®¿é—®ç½‘é¡µ...")
        try:
            return self.ghost.browse_and_extract(url, take_screenshot=take_screenshot)
        except Exception as e:
            logger.error(f"âŒ æ·±åº¦æµè§ˆå¤±è´¥: {e}")
            return self.read_web_page(url)
