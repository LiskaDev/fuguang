"""
MemorySkills â€” ğŸ§  è®°å¿†ç±»æŠ€èƒ½
é•¿æœŸè®°å¿†ï¼ˆå‘é‡æ•°æ®åº“ï¼‰ã€çŸ¥è¯†åå™¬ã€è®°å¿†ç®¡ç†
"""
import logging

logger = logging.getLogger("fuguang.skills")

_MEMORY_TOOLS_SCHEMA = [
    {"type":"function","function":{"name":"save_memory","description":"å°†ç”¨æˆ·çš„é‡è¦ä¿¡æ¯å­˜å…¥é•¿æœŸè®°å¿†ã€‚","parameters":{"type":"object","properties":{"content":{"type":"string","description":"è¦è®°å¿†çš„å†…å®¹"},"importance":{"type":"integer","description":"é‡è¦ç¨‹åº¦(1-5)"}},"required":["content"]}}},
    {"type":"function","function":{"name":"save_to_long_term_memory","description":"ã€é•¿æœŸè®°å¿†ã€‘å°†é‡è¦ä¿¡æ¯æ°¸ä¹…ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ã€‚ä½ åº”è¯¥ä¸»åŠ¨åˆ¤æ–­ä½•æ—¶è°ƒç”¨æ­¤å·¥å…·ã€‚","parameters":{"type":"object","properties":{"content":{"type":"string","description":"è¦è®°ä½çš„å†…å®¹"},"category":{"type":"string","description":"åˆ†ç±»","enum":["preference","fact","task","event","general"]}},"required":["content"]}}},
    {"type":"function","function":{"name":"ingest_knowledge_file","description":"ã€çŸ¥è¯†åº“ã€‘è¯»å–æœ¬åœ°æ–‡ä»¶å¹¶å­¦ä¹ å…¶å†…å®¹ã€‚æ”¯æŒ PDF, Word, TXT, Markdown, Python, JSONç­‰ã€‚","parameters":{"type":"object","properties":{"file_path":{"type":"string","description":"æ–‡ä»¶çš„ç»å¯¹è·¯å¾„"}},"required":["file_path"]}}},
    {"type":"function","function":{"name":"forget_knowledge","description":"ã€åˆ é™¤çŸ¥è¯†ã€‘ä»çŸ¥è¯†åº“ä¸­åˆ é™¤æ¥è‡ªç‰¹å®šæ–‡ä»¶çš„æ‰€æœ‰å†…å®¹ã€‚","parameters":{"type":"object","properties":{"source_name":{"type":"string","description":"è¦åˆ é™¤çš„æ–‡ä»¶å"}},"required":["source_name"]}}},
    {"type":"function","function":{"name":"forget_memory","description":"ã€é—å¿˜è®°å¿†ã€‘ä»å¯¹è¯è®°å¿†ä¸­åˆ é™¤åŒ…å«ç‰¹å®šå…³é”®è¯çš„è®°å¿†ã€‚","parameters":{"type":"object","properties":{"keyword":{"type":"string","description":"è¦åŒ¹é…çš„å…³é”®è¯"}},"required":["keyword"]}}},
    {"type":"function","function":{"name":"list_learned_files","description":"ã€æŸ¥çœ‹çŸ¥è¯†åº“ã€‘åˆ—å‡ºå·²å­¦ä¹ çš„æ‰€æœ‰æ–‡ä»¶åŠå…¶ç¢ç‰‡æ•°é‡ã€‚","parameters":{"type":"object","properties":{}}}},
]


class MemorySkills:
    """è®°å¿†ç±»æŠ€èƒ½ Mixin"""
    _MEMORY_TOOLS = _MEMORY_TOOLS_SCHEMA

    def save_to_long_term_memory(self, content: str, category: str = "general") -> str:
        """
        ã€é•¿æœŸè®°å¿†ã€‘å°†é‡è¦ä¿¡æ¯æ°¸ä¹…ä¿å­˜åˆ°ChromaDBå‘é‡æ•°æ®åº“ã€‚
        
        åŠŸèƒ½ï¼šAIä¸»åŠ¨åˆ¤æ–­é‡è¦ä¿¡æ¯å¹¶æ°¸ä¹…è®°å¿†ï¼Œæ”¯æŒå‘é‡æ£€ç´¢
        åˆ†ç±»ï¼špreference(åå¥½) / fact(äº‹å®) / task(ä»»åŠ¡æ•™è®­) / event(äº‹ä»¶) / general(é€šç”¨)
        
        Args:
            content: è¦è®°ä½çš„å†…å®¹
            category: è®°å¿†åˆ†ç±»ï¼ˆé»˜è®¤generalï¼‰
            
        Returns:
            ä¿å­˜ç»“æœ
        """
        if not self.memory:
            return "âŒ é•¿æœŸè®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜"
        logger.info(f"ğŸ§  [è®°å¿†] AI è¯·æ±‚ä¿å­˜: '{content[:50]}...' (åˆ†ç±»: {category})")
        try:
            result = self.memory.add_memory(content, category=category)
            self.mouth.speak("å¥½çš„ï¼Œæˆ‘è®°ä½äº†")
            return result
        except Exception as e:
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

    def ingest_knowledge_file(self, file_path: str) -> str:
        """
        ã€çŸ¥è¯†åå™¬ã€‘è¯»å–æœ¬åœ°æ–‡ä»¶å¹¶å­¦ä¹ å…¶å†…å®¹ï¼Œæ”¯æŒå¤šç§æ ¼å¼ã€‚
        
        æ”¯æŒæ ¼å¼ï¼šPDF, Word, TXT, Markdown, Python, JSONç­‰
        å¤„ç†æµç¨‹ï¼šæ–‡æ¡£åˆ†å— â†’ å‘é‡åµŒå…¥ â†’ å­˜å‚¨åˆ°ChromaDB
        
        Args:
            file_path: æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
            
        Returns:
            å­¦ä¹ ç»“æœï¼ˆæˆåŠŸç¢ç‰‡æ•°ï¼‰
        """
        if not self.eater:
            return "âŒ çŸ¥è¯†åå™¬ç³»ç»Ÿæœªåˆå§‹åŒ–"
        logger.info(f"ğŸ“š [çŸ¥è¯†åº“] AI è¯·æ±‚åå™¬æ–‡ä»¶: {file_path}")
        self.mouth.speak("å¥½çš„ï¼Œè®©æˆ‘æ¥å­¦ä¹ è¿™ä¸ªæ–‡ä»¶...")
        try:
            result = self.eater.ingest_file(file_path)
            if result.startswith("âœ…"):
                self.mouth.speak("å­¦ä¹ å®Œæˆï¼Œæˆ‘å·²ç»è®°ä½äº†æ–‡ä»¶å†…å®¹")
            return result
        except Exception as e:
            return f"âŒ åå™¬å¤±è´¥: {str(e)}"

    def forget_knowledge(self, source_name: str) -> str:
        """
        ã€åˆ é™¤çŸ¥è¯†ã€‘ä»çŸ¥è¯†åº“ä¸­åˆ é™¤æ¥è‡ªç‰¹å®šæ–‡ä»¶çš„æ‰€æœ‰å†…å®¹ã€‚
        
        åŠŸèƒ½ï¼šæŒ‰æ¥æºæ‰¹é‡åˆ é™¤å‘é‡è®°å½•
        åº”ç”¨ï¼šæ–‡ä»¶å·²è¿‡æœŸã€ä¿¡æ¯é”™è¯¯ã€æ¸…ç†ç©ºé—´
        
        Args:
            source_name: è¦åˆ é™¤çš„æ–‡ä»¶åï¼ˆéœ€å®Œå…¨åŒ¹é…ï¼‰
            
        Returns:
            åˆ é™¤ç»“æœï¼ˆåˆ é™¤æ•°é‡ï¼‰
        """
        if not self.memory:
            return "âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–"
        logger.info(f"ğŸ—‘ï¸ [çŸ¥è¯†åº“] AI è¯·æ±‚åˆ é™¤æ¥è‡ª '{source_name}' çš„çŸ¥è¯†")
        self.mouth.speak(f"å¥½çš„ï¼Œè®©æˆ‘å¿˜æ‰{source_name}çš„å†…å®¹...")
        return self.memory.delete_knowledge_by_source(source_name)

    def forget_memory(self, keyword: str) -> str:
        """
        ã€é—å¿˜è®°å¿†ã€‘ä»å¯¹è¯è®°å¿†ä¸­åˆ é™¤åŒ…å«ç‰¹å®šå…³é”®è¯çš„è®°å¿†ã€‚
        
        åŠŸèƒ½ï¼šæŒ‰å†…å®¹å…³é”®è¯æ¨¡ç³ŠåŒ¹é…åˆ é™¤
        åº”ç”¨ï¼šç”¨æˆ·è¦æ±‚é—å¿˜æŸäº‹ã€åˆ é™¤éšç§ä¿¡æ¯
        
        Args:
            keyword: è¦åŒ¹é…çš„å…³é”®è¯ï¼ˆæ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼‰
            
        Returns:
            åˆ é™¤ç»“æœï¼ˆåˆ é™¤æ•°é‡ï¼‰
        """
        if not self.memory:
            return "âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–"
        logger.info(f"ğŸ—‘ï¸ [å¯¹è¯è®°å¿†] AI è¯·æ±‚é—å¿˜åŒ…å« '{keyword}' çš„è®°å¿†")
        self.mouth.speak(f"å¥½çš„ï¼Œè®©æˆ‘å¿˜æ‰å…³äº{keyword}çš„äº‹æƒ…...")
        return self.memory.forget_memory_by_content(keyword)

    def list_learned_files(self) -> str:
        """
        ã€æŸ¥çœ‹çŸ¥è¯†åº“ã€‘åˆ—å‡ºå·²å­¦ä¹ çš„æ‰€æœ‰æ–‡ä»¶åŠå…¶ç¢ç‰‡æ•°é‡ã€‚
        
        åŠŸèƒ½ï¼šç»Ÿè®¡çŸ¥è¯†åº“å†…å®¹ï¼ŒæŸ¥çœ‹å·²åå™¬çš„æ–‡ä»¶åˆ—è¡¨
        æ˜¾ç¤ºï¼šæ–‡ä»¶å + ç¢ç‰‡æ•° + æ€»ä½“ç»Ÿè®¡
        
        Returns:
            æ–‡ä»¶åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
        """
        if not self.memory:
            return "âŒ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–"
        sources = self.memory.list_knowledge_sources()
        if not sources:
            return "ğŸ“š çŸ¥è¯†åº“æ˜¯ç©ºçš„ï¼Œæˆ‘è¿˜æ²¡æœ‰å­¦ä¹ è¿‡ä»»ä½•æ–‡ä»¶"
        lines = ["ğŸ“š æˆ‘å·²å­¦ä¹ çš„æ–‡ä»¶ï¼š"]
        for s in sources:
            lines.append(f"  â€¢ {s['source']} ({s['chunk_count']} ä¸ªç¢ç‰‡)")
        stats = self.memory.get_stats()
        lines.append(f"\nğŸ“Š ç»Ÿè®¡ï¼šçŸ¥è¯†åº“ {stats['knowledge_count']} æ¡ | å¯¹è¯è®°å¿† {stats['memories_count']} æ¡")
        return "\n".join(lines)
